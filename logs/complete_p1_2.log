['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=0']
Command line arguments: Namespace(channels=[0], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 01:13:47.719375
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net0
evaluation:
    online_training: False
    model: net0

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.784949248
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 202.260870361 168.356483459
20 485.263098145 456.906463623
30 720.617132568 687.411590576
40 970.997924805 928.310668945
50 1267.06549072 1210.00848389
60 1645.51918945 1567.70336914
70 2171.50119629 2065.12841797
80 2995.66479492 2853.98950195
90 4635.590625 4468.23974609
100 101397.328125 96893.890625
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net0
Model name for the evaluation phase:  net0
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.61583[0m     [32m1.27002[0m    1.27229      0.46132  700.22s
      2     [36m0.53886[0m     [32m0.99254[0m    0.54291      0.39216  730.40s
      3     [36m0.49778[0m     1.06297    0.46830      0.41880  694.87s
      4     [36m0.42514[0m     1.15314    0.36868      0.45065  707.24s
      5     [36m0.33259[0m     2.14483    0.15507      0.48933  706.86s
      6     [36m0.21977[0m     2.42198    0.09074      0.40949  714.71s
      7     [36m0.17925[0m     3.40246    0.05268      0.43870  687.96s
Early stopping.
Best valid loss was 0.992544 at epoch 2.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.39118852459
Error rate (%):  60.881147541
yVal [0 1 1 ..., 1 1 0]
[[5727 1553]
 [7360    0]]
roc_auc: 0.508378560977
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=1']
Command line arguments: Namespace(channels=[1], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 03:16:20.953322
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net0
evaluation:
    online_training: False
    model: net0

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.784236544
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 206.928393555 172.378547668
20 498.400262451 474.416625977
30 733.650720215 708.896759033
40 974.438952637 945.946472168
50 1245.57879639 1211.81964111
60 1575.56948242 1534.62207031
70 2010.92930908 1959.51019287
80 2664.01162109 2593.76342773
90 3932.5364502 3832.79516602
100 71591.0625 60304.03125
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net0
Model name for the evaluation phase:  net0
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.59360[0m     [32m0.97279[0m    1.63816      0.45304  720.41s
      2     [36m0.53373[0m     1.32061    0.40415      0.45167  725.50s
      3     [36m0.44885[0m     1.34959    0.33258      0.42512  698.60s
      4     [36m0.40735[0m     [32m0.72302[0m    0.56340      0.48412  726.71s
      5     [36m0.26312[0m     1.37382    0.19152      0.49274  730.75s
      6     [36m0.15701[0m     2.97565    0.05277      0.43613  713.78s
      7     [36m0.14339[0m     2.16229    0.06631      0.51084  717.77s
      8     [36m0.09385[0m     2.38231    0.03940      0.48463  732.53s
      9     [36m0.08175[0m     2.15546    0.03793      0.48668  720.83s
Early stopping.
Best valid loss was 0.723024 at epoch 4.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.476297814208
Error rate (%):  52.3702185792
yVal [0 1 1 ..., 1 1 0]
[[5568 1712]
 [5955 1405]]
roc_auc: 0.630574888766
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=2']
Command line arguments: Namespace(channels=[2], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 05:23:53.833601
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net0
evaluation:
    online_training: False
    model: net0

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.78422016
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 213.738221741 179.564910889
20 508.706988525 488.186553955
30 740.875622559 721.752166748
40 972.295471191 952.076049805
50 1226.75701904 1203.95013428
60 1529.04313965 1501.61279297
70 1918.31774902 1884.3873291
80 2484.309375 2442.01074219
90 3547.98891602 3499.03417969
100 119907.929688 146484.890625
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net0
Model name for the evaluation phase:  net0
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.46761[0m     [32m0.81337[0m    1.80436      0.42119  722.19s
      2     [36m0.56469[0m     0.86657    0.65164      0.40044  705.46s
      3     [36m0.50133[0m     0.97646    0.51342      0.41248  706.52s
      4     [36m0.45017[0m     1.21340    0.37100      0.39353  702.53s
      5     [36m0.37500[0m     1.52009    0.24669      0.37620  721.45s
      6     [36m0.24148[0m     2.03106    0.11889      0.40121  702.11s
Early stopping.
Best valid loss was 0.813371 at epoch 1.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.423224043716
Error rate (%):  57.6775956284
yVal [0 1 1 ..., 1 1 0]
[[6196 1084]
 [7360    0]]
roc_auc: 0.423550936156
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=3']
Command line arguments: Namespace(channels=[3], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 06:53:31.248752
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net0
evaluation:
    online_training: False
    model: net0

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.78385152
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 19.6690460205 14.0969910622
20 116.733595276 99.3462142944
30 468.487338257 443.317764282
40 731.003540039 706.207275391
50 987.08303833 959.834991455
60 1271.64260254 1238.17504883
70 1621.35058594 1579.47271729
80 2106.56230469 2052.5390625
90 2961.25544434 2887.56567383
100 141686.875 89376.015625
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net0
Model name for the evaluation phase:  net0
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.23916[0m     [32m0.95001[0m    1.30437      0.39464  688.91s
      2     [36m0.53383[0m     [32m0.87128[0m    0.61270      0.44339  711.91s
      3     [36m0.42860[0m     1.49675    0.28636      0.44049  704.74s
      4     [36m0.35128[0m     2.45221    0.14325      0.39942  699.13s
      5     [36m0.30064[0m     2.40689    0.12491      0.37970  718.93s
      6     [36m0.23667[0m     4.31508    0.05485      0.40642  730.86s
      7     [36m0.19726[0m     4.93574    0.03997      0.42333  733.57s
Early stopping.
Best valid loss was 0.871278 at epoch 2.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.447267759563
Error rate (%):  55.2732240437
yVal [0 1 1 ..., 1 1 0]
[[2975 4305]
 [3787 3573]]
roc_auc: 0.434563183081
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=4']
Command line arguments: Namespace(channels=[4], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 08:35:59.725668
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net0
evaluation:
    online_training: False
    model: net0

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.784744448
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 239.421202087 199.921806335
20 574.585070801 543.65411377
30 843.210821533 809.075256348
40 1119.16928711 1078.46875
50 1437.58898926 1387.05267334
60 1842.8963623 1777.23901367
70 2410.89768066 2320.98596191
80 3299.05410156 3167.82080078
90 4954.51757812 4739.92138672
100 52009.53125 42999.078125
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net0
Model name for the evaluation phase:  net0
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.62288[0m     [32m0.74789[0m    2.16995      0.55447  709.90s
      2     [36m0.59955[0m     [32m0.70815[0m    0.84664      0.49419  720.27s
      3     [36m0.54789[0m     0.71992    0.76104      0.50794  714.66s
      4     [36m0.44154[0m     1.34102    0.32925      0.48694  741.70s
      5     [36m0.28307[0m     2.93785    0.09635      0.45842  733.10s
      6     [36m0.17915[0m     3.02983    0.05913      0.46055  730.27s
      7     [36m0.12036[0m     5.93223    0.02029      0.45970  732.47s
Early stopping.
Best valid loss was 0.708152 at epoch 2.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.496106557377
Error rate (%):  50.3893442623
yVal [0 1 1 ..., 1 1 0]
[[2505 4775]
 [2602 4758]]
roc_auc: 0.488093430856
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=5']
Command line arguments: Namespace(channels=[5], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 10:18:20.620295
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net0
evaluation:
    online_training: False
    model: net0

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.785723392
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 235.012228394 192.875953674
20 566.306152344 529.812561035
30 831.834051514 789.432739258
40 1104.28349609 1051.81738281
50 1420.10662842 1351.90142822
60 1824.84020996 1734.17260742
70 2397.64912109 2271.95996094
80 3280.87207031 3104.30908203
90 4885.48979492 4615.77099609
100 55591.203125 52662.2460938
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net0
Model name for the evaluation phase:  net0
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.85168[0m     [32m0.83041[0m    2.22985      0.49932  641.59s
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run2.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient2', '--channels=0']
      2     [36m0.60530[0m     [32m0.78044[0m    0.77559      0.55379  653.86s
      3     [36m0.54829[0m     0.80217    0.68351      0.53569  692.66s
      4     [36m0.46914[0m     [32m0.76114[0m    0.61636      0.48694  704.76s
      5     [36m0.32555[0m     1.86282    0.17476      0.44689  704.65s
      6     [36m0.20194[0m     1.46001    0.13831      0.38277  661.20s
      7     [36m0.12904[0m     3.70341    0.03484      0.45543  643.42s
      8     [36m0.10273[0m     4.64626    0.02211      0.45714  691.20s
      9     [36m0.07785[0m     4.53519    0.01717      0.46448  710.77s
Early stopping.
Best valid loss was 0.761140 at epoch 4.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.486407103825
Error rate (%):  51.3592896175
yVal [0 1 1 ..., 1 1 0]
[[3834 3446]
 [4073 3287]]
roc_auc: 0.556391449922
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=6']
Command line arguments: Namespace(channels=[6], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 12:18:33.157497
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net3
evaluation:
    online_training: False
    model: net3

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.784863232
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 202.214730835 163.390800476
20 485.357543945 447.911590576
30 715.467364502 669.537719727
40 956.924304199 896.82824707
50 1245.06646729 1163.88885498
60 1624.86760254 1511.64050293
70 2166.63815918 2006.6552124
80 3004.99970703 2778.06762695
90 4614.8956543 4242.0456543
100 66751.359375 59361.5703125
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net3
Model name for the evaluation phase:  net3
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.35842[0m     [32m0.67363[0m    2.01656      0.46738  647.92s
      2     [36m0.66538[0m     [32m0.62435[0m    1.06571      0.64062  641.38s
      3     [36m0.62471[0m     [32m0.62319[0m    1.00244      0.65745  641.55s
      4     [36m0.58707[0m     0.67542    0.86919      0.64336  642.37s
      5     [36m0.57482[0m     0.67959    0.84583      0.64028  647.60s
      6     [36m0.54971[0m     0.72583    0.75735      0.43588  642.13s
      7     [36m0.52641[0m     0.87838    0.59930      0.57044  639.87s
      8     [36m0.51138[0m     0.74393    0.68740      0.62961  676.40s
Early stopping.
Best valid loss was 0.623191 at epoch 3.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.650136612022
Error rate (%):  34.9863387978
yVal [0 1 1 ..., 1 1 0]
[[3672 3608]
 [1514 5846]]
roc_auc: 0.634691139363
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=7']
Command line arguments: Namespace(channels=[7], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 14:03:12.022784
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net3
evaluation:
    online_training: False
    model: net3

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.785350656
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 185.573376465 149.823059082
20 446.898638916 411.701080322
30 662.398498535 618.625640869
40 892.103625488 835.423828125
50 1170.04150391 1093.59197998
60 1538.95534668 1432.44165039
70 2070.14841309 1921.18255615
80 2918.14931641 2705.77734375
90 4599.92104492 4269.7043457
100 65353.1796875 57503.8945312
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net3
Model name for the evaluation phase:  net3
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.37178[0m     [32m0.98421[0m    1.39378      0.46363  677.26s
      2     [36m0.67161[0m     [32m0.95854[0m    0.70066      0.46422  684.28s
      3     [36m0.63239[0m     [32m0.82088[0m    0.77038      0.46559  688.73s
      4     [36m0.60799[0m     [32m0.69458[0m    0.87533      0.45996  676.86s
      5     [36m0.59735[0m     [32m0.61160[0m    0.97669      0.56668  682.80s
      6     [36m0.56358[0m     0.62925    0.89563      0.55294  674.46s
      7     [36m0.52915[0m     [32m0.59460[0m    0.88992      0.62107  680.91s
      8     [36m0.50028[0m     [32m0.57044[0m    0.87701      0.65027  707.46s
      9     [36m0.47542[0m     0.57834    0.82205      0.65497  693.14s
     10     [36m0.44498[0m     0.70186    0.63401      0.66692  689.16s
     11     [36m0.42287[0m     0.69641    0.60721      0.67059  707.73s
     12     [36m0.39958[0m     0.62440    0.63994      0.70833  686.97s
Early stopping.
Best valid loss was 0.570437 at epoch 8.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.654713114754
Error rate (%):  34.5286885246
yVal [0 1 1 ..., 1 1 0]
[[4080 3200]
 [1855 5505]]
roc_auc: 0.741380886437
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=8']
Command line arguments: Namespace(channels=[8], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 16:39:29.060449
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net3
evaluation:
    online_training: False
    model: net3

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.786018304
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 182.433731079 149.94278717
20 436.049041748 410.029296875
30 635.802856445 606.535400391
40 835.57677002 801.683410645
50 1056.74621582 1016.02960205
60 1321.59230957 1272.10205078
70 1665.66821289 1603.8125
80 2168.0465332 2087.17016602
90 3108.63288574 2996.27380371
100 59862.1054688 57871.4179688
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net3
Model name for the evaluation phase:  net3
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.16485[0m     [32m1.33621[0m    0.87176      0.46363  657.42s
      2     [36m0.65093[0m     1.60760    0.40491      0.46422  644.82s
      3     [36m0.62483[0m     1.74735    0.35759      0.46559  645.76s
      4     [36m0.60427[0m     1.57691    0.38320      0.46551  645.74s
      5     [36m0.58490[0m     1.73476    0.33716      0.46320  651.99s
Early stopping.
Best valid loss was 1.336210 at epoch 1.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.461475409836
Error rate (%):  53.8524590164
yVal [0 1 1 ..., 1 1 0]
[[6756  524]
 [7360    0]]
roc_auc: 0.491902519186
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=9']
Command line arguments: Namespace(channels=[9], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 17:50:54.712147
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net3
evaluation:
    online_training: False
    model: net3

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.78721024
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 3.73858091831 3.27668011189
20 8.95421485901 8.65685558319
30 13.5715697289 13.20033741
40 19.6790660858 19.0048999786
50 43.6948184967 34.7788333893
60 449.341595459 388.074157715
70 780.715905762 715.159332275
80 1201.33637695 1117.43395996
90 1923.547229 1805.91333008
100 43853.8789062 40357.3945312
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net3
Model name for the evaluation phase:  net3
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.88985[0m     [32m0.89523[0m    0.99400      0.44177  678.20s
      2     [36m0.68980[0m     [32m0.74062[0m    0.93138      0.43835  675.34s
      3     [36m0.67399[0m     [32m0.70925[0m    0.95029      0.44416  658.19s
      4     [36m0.65990[0m     0.75975    0.86857      0.36877  644.38s
      5     [36m0.65018[0m     0.76376    0.85128      0.47251  646.96s
      6     [36m0.62421[0m     0.86780    0.71931      0.50529  649.57s
      7     [36m0.58858[0m     0.90697    0.64895      0.52553  649.29s
Early stopping.
Best valid loss was 0.709248 at epoch 3.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.437295081967
Error rate (%):  56.2704918033
yVal [0 1 1 ..., 1 1 0]
[[1090 6190]
 [2048 5312]]
roc_auc: 0.364425428512
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=10']
Command line arguments: Namespace(channels=[10], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 19:24:54.575437
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net3
evaluation:
    online_training: False
    model: net3

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.786681856
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 184.185713196 152.952148438
20 440.024975586 416.685943604
30 641.064581299 616.230438232
40 840.985620117 812.821044922
50 1060.82244873 1027.43164062
60 1320.46096191 1279.14282227
70 1649.28624268 1598.09313965
80 2109.55322266 2045.45068359
90 2906.99501953 2825.17199707
100 41643.4882812 36225.46875
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net3
Model name for the evaluation phase:  net3
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.14326[0m     [32m1.54928[0m    0.73793      0.46363  647.98s
      2     [36m0.64918[0m     [32m1.12207[0m    0.57855      0.46422  648.27s
      3     [36m0.61397[0m     [32m0.84404[0m    0.72742      0.41402  646.83s
      4     [36m0.58013[0m     0.86148    0.67342      0.41991  648.86s
      5     [36m0.55884[0m     1.05121    0.53162      0.44843  654.26s
      6     [36m0.52996[0m     1.16651    0.45431      0.46047  648.35s
      7     [36m0.50285[0m     1.17794    0.42688      0.47678  647.34s
Early stopping.
Best valid loss was 0.844042 at epoch 3.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.416461748634
Error rate (%):  58.3538251366
yVal [0 1 1 ..., 1 1 0]
[[5873 1407]
 [7136  224]]
roc_auc: 0.470394553646
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=11']
Command line arguments: Namespace(channels=[11], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 20:57:54.594352
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net3
evaluation:
    online_training: False
    model: net3

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.787316736
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 175.594898987 145.517463684
20 419.360888672 395.677886963
30 609.753845215 583.460235596
40 797.140246582 765.498535156
50 1000.32189941 962.170196533
60 1235.86208496 1189.52197266
70 1531.12805176 1473.54846191
80 1943.29196777 1868.76367188
90 2665.28051758 2562.52746582
100 34311.5273438 30092.4199219
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net3
Model name for the evaluation phase:  net3
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.06678[0m     [32m1.45851[0m    0.73142      0.46363  645.97s
      2     [36m0.62059[0m     [32m1.17398[0m    0.52862      0.46363  645.45s
      3     [36m0.55873[0m     [32m0.89701[0m    0.62288      0.36621  645.12s
      4     [36m0.50215[0m     0.90646    0.55397      0.33043  645.87s
      5     [36m0.47291[0m     1.27838    0.36993      0.40138  650.46s
      6     [36m0.45627[0m     1.27998    0.35647      0.39071  644.02s
      7     [36m0.43078[0m     1.38109    0.31191      0.41564  644.38s
Early stopping.
Best valid loss was 0.897006 at epoch 3.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.366120218579
Error rate (%):  63.3879781421
yVal [0 1 1 ..., 1 1 0]
[[5360 1920]
 [7360    0]]
roc_auc: 0.470052024233
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=12']
Command line arguments: Namespace(channels=[12], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-26 22:30:38.516684
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net3
evaluation:
    online_training: False
    model: net3

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.78761984
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 197.847105408 162.232131958
20 466.161206055 435.430114746
30 668.632995605 633.256835938
40 862.47142334 820.440124512
50 1068.59735107 1017.74472046
60 1307.13903809 1244.34411621
70 1610.01538086 1529.31481934
80 2051.1934082 1942.77392578
90 2874.82258301 2724.64428711
100 68176.640625 59867.6914062
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net3
Model name for the evaluation phase:  net3
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.08083[0m     [32m1.18927[0m    0.90882      0.50384  661.10s
      2     [36m0.64062[0m     [32m0.81185[0m    0.78909      0.52783  648.53s
      3     [36m0.60523[0m     [32m0.68432[0m    0.88442      0.58103  652.31s
      4     [36m0.56995[0m     [32m0.59577[0m    0.95666      0.67580  694.45s
      5     [36m0.53981[0m     [32m0.58576[0m    0.92155      0.67990  700.77s
      6     [36m0.51910[0m     [32m0.57458[0m    0.90344      0.67794  683.48s
      7     [36m0.50933[0m     0.60531    0.84144      0.66359  683.24s
      8     [36m0.48738[0m     0.62912    0.77470      0.61971  683.93s
      9     [36m0.47277[0m     0.65557    0.72116      0.63926  685.77s
     10     [36m0.45094[0m     0.68749    0.65593      0.62560  681.49s
Early stopping.
Best valid loss was 0.574581 at epoch 6.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.679030054645
Error rate (%):  32.0969945355
yVal [0 1 1 ..., 1 1 0]
[[3546 3734]
 [ 965 6395]]
roc_auc: 0.761609485114
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=13']
Command line arguments: Namespace(channels=[13], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-27 00:41:49.840093
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net3
evaluation:
    online_training: False
    model: net3

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.787521536
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 200.816160583 166.028656006
20 476.097589111 449.419219971
30 685.35871582 656.065368652
40 886.69173584 852.978759766
50 1100.39276123 1060.0045166
60 1345.78920898 1295.31213379
70 1653.55772705 1589.07421875
80 2092.56630859 2005.52539062
90 2905.67011719 2776.49841309
100 37327.25 36168.203125
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net3
Model name for the evaluation phase:  net3
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.09391[0m     [32m0.79434[0m    1.37713      0.54568  686.36s
      2     [36m0.64003[0m     0.88456    0.72357      0.55763  685.55s
      3     [36m0.60596[0m     [32m0.75790[0m    0.79952      0.57915  690.19s
      4     [36m0.58102[0m     [32m0.61426[0m    0.94587      0.55806  692.68s
      5     [36m0.55638[0m     0.82278    0.67622      0.50623  698.59s
      6     [36m0.53334[0m     1.00789    0.52917      0.49667  684.42s
      7     [36m0.51069[0m     1.28290    0.39807      0.49804  679.90s
      8     [36m0.48051[0m     1.63969    0.29305      0.48446  686.41s
Early stopping.
Best valid loss was 0.614263 at epoch 4.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.560109289617
Error rate (%):  43.9890710383
yVal [0 1 1 ..., 1 1 0]
[[3984 3296]
 [3144 4216]]
roc_auc: 0.649098697668
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=14']
Command line arguments: Namespace(channels=[14], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-27 02:31:40.928018
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net3
evaluation:
    online_training: False
    model: net3

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.787615744
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 192.278979492 159.171096802
20 454.51661377 429.81652832
30 651.260583496 624.928649902
40 837.994689941 807.764465332
50 1032.79595947 997.46282959
60 1252.28759766 1210.24035645
70 1520.01416016 1466.78344727
80 1885.53779297 1816.83203125
90 2515.98427734 2416.08642578
100 43412.1367188 33402.015625
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net3
Model name for the evaluation phase:  net3
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.05252[0m     [32m2.40612[0m    0.43743      0.49932  680.21s
      2     [36m0.64880[0m     3.75811    0.17264      0.49932  677.21s
      3     [36m0.61439[0m     3.72247    0.16505      0.49932  674.67s
      4     [36m0.58305[0m     2.80377    0.20795      0.49932  671.86s
      5     [36m0.56267[0m     [32m1.71873[0m    0.32737      0.50649  685.31s
      6     [36m0.54827[0m     [32m1.16210[0m    0.47180      0.54218  681.51s
      7     [36m0.52341[0m     [32m0.68518[0m    0.76391      0.64481  679.06s
      8     [36m0.49904[0m     [32m0.65058[0m    0.76706      0.47883  680.94s
      9     [36m0.47823[0m     0.75355    0.63464      0.59332  679.63s
     10     [36m0.45284[0m     0.78987    0.57331      0.57616  708.92s
     11     [36m0.43313[0m     1.36728    0.31678      0.47908  710.68s
     12     [36m0.41137[0m     0.81601    0.50412      0.56327  712.03s
Early stopping.
Best valid loss was 0.650583 at epoch 8.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[1 1 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.48381147541
Error rate (%):  51.618852459
yVal [0 1 1 ..., 1 1 0]
[[3672 3608]
 [3949 3411]]
roc_auc: 0.657294683917
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run1.pickle', '--config-filename=config.yml', '--no-channels=1', '--target-gpu=gpu0', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1', '--channels=15']
Command line arguments: Namespace(channels=[15], chosen_validation_ratio=0.2, config_filename='config.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run1.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu0')
Git reference:  Timestamp: 2016-09-27 05:07:42.003668
Hostname: kat
gpu0
Configuration 'config.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 512
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net3
evaluation:
    online_training: False
    model: net3

end Configuration
Loading and preprocessing data...
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels
/home/eavsteen/seizure_detection/data/train_2/2_
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365]
292
[106 259  45  26  78 347  90 311 239   6 120 141 263 286 299 210 294 101
 221 140 142 199  59 293 302 254  68 332 113 191 124 102  15  37  54   5
  60 132 264  64 206 303 212 260  20 305 213 214 240  65 173 220 235 164
  92  55  52 135  89  76 326 270   7 100 327 343  56 122 219 159  74 170
 114 295  63 241 306 317 245 329  21 144 146  49 362 341 309 204 269 281
 289  22 208 229 200 136 116  66 134  12 354 158 296 175  17 217 145 318
 234 218 103 356 198 284 268 179 300 150 225  81   1 153   8 266 247 155
 126 283 133 272 255  33 345  34 365  97  85 215 310 162 358 186 168 108
  46 304 181  73 137 348 167 282  29 261 248 298 320  27 231 176 156 171
 138 190 276 246 252  35 230 216 233 236  44 357 129  93 111 166 250 224
  18 258  79 322  71 228 307 352 196 160 360 161  83 189 363 118 331 237
 342 110 149 157 152  16 238  75 109 297 205 253 139 359   4  96  14  61
  67 316 194 154 223 280 355 340  40 112  13 107 226 278   3 249 125  24
  30  77 232 188 184 338 274 346  19 312 350 182 324  80  51   2  11 104
 271  86  10  36 349  58  41  50 209 328 287 301 123 222  62 275 130 187
  23  43   0 201 308  98 178 256  94 336  95 319 169  69  48 207 279 227
 148 143 180 131]
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
normal i 365
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]
20
[ 5  2 19 16 11 22 17 24 23 14  1 10 13  8  6 18  4  9  7 20]
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 366 no seizure hours and 25 seizure hours
Memory usage (GB): 0.786046976
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 74
percentiles:
0 0.0 0.0
10 195.569773865 161.052391052
20 461.383886719 434.366851807
30 660.075195312 630.937469482
40 847.686938477 814.774291992
50 1042.60760498 1005.25018311
60 1261.60791016 1217.76916504
70 1528.51779785 1475.94433594
80 1895.11066895 1831.36975098
90 2537.23972168 2455.97021484
100 29197.0292969 29615.0136719
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
size 73200
no_normal 366
no_seizure 25
no_samples_normal_ph 100
no_samples_seizure_ph 1464
Histogram:
[36600 36600]
magnitudes.shape (73200,)
labels.shape (73200,)
Ratio validation: 0.2
xVal.shape (14640,)
yVal.shape (14640,)
xTrain.shape (58560,)
yTrain.shape (58560,)
xVal.shape (14640, 2)
yVal.shape (14640,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  net3
Model name for the evaluation phase:  net3
Training model...
# Neural Network with 149506 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x512x64
  1          64x512x64
  2          64x512x64
  3          64x256x32
  4          64x256x32
  5          64x256x32
  6          64x256x32
  7          64x128x16
  8          64x128x16
  9          64x128x16
 10          2x128x16
 11          2
 12          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m1.06075[0m     [32m1.46363[0m    0.72474      0.46363  656.65s
      2     [36m0.65035[0m     [32m0.87683[0m    0.74171      0.46422  646.32s
      3     [36m0.61458[0m     [32m0.65870[0m    0.93302      0.49411  647.70s
      4     [36m0.56810[0m     0.67655    0.83970      0.49735  649.55s
      5     [36m0.53249[0m     0.67971    0.78340      0.55166  654.20s
      6     [36m0.50641[0m     0.70286    0.72049      0.55678  648.95s
      7     [36m0.48057[0m     0.71793    0.66938      0.57061  646.86s
Early stopping.
Best valid loss was 0.658703 at epoch 3.
Loaded parameters to layer 'conv2d1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 64).
Loaded parameters to layer 'conv2d2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d5' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d5' (shape 64).
Loaded parameters to layer 'conv2d6' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d6' (shape 64).
Loaded parameters to layer 'conv2d9' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d9' (shape 64).
Loaded parameters to layer 'conv2d10' (shape 2x64x3x3).
Loaded parameters to layer 'conv2d10' (shape 2).
Saving model...
Validating...
probabilities.shape (14640, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0]
Ground Truth:
[1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0]
Performance on relevant data
Accuracy validation:  0.504030054645
Error rate (%):  49.5969945355
yVal [0 1 1 ..., 1 1 0]
[[4564 2716]
 [4545 2815]]
roc_auc: 0.592195301302
