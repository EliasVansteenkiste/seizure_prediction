['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_0']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_0'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 12:21:03.447634
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_0']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [0]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.816160768
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 199.036781311 184.038919067
20 483.221002197 465.519171143
30 718.880554199 694.377087402
40 969.482617188 933.868884277
50 1265.8637085 1213.74743652
60 1644.84228516 1568.92561035
70 2171.59033203 2061.92285156
80 2997.35341797 2842.94628906
90 4640.41015625 4440.24106445
100 101397.328125 96893.890625
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.65427[0m     [32m0.70621[0m    0.92645      0.60537  74.43s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.59038[0m     2.23768    0.26384      0.51762  77.79s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.57976[0m     1.07656    0.53853      0.60825  76.66s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.55655[0m     0.74567    0.74637      0.53462  76.35s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.51043[0m     0.91613    0.55716      0.59204  76.68s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.47261[0m     0.83284    0.56746      0.64588  76.76s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.706208 at epoch 1.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.896127466498
Error rate (%):  10.3872533502
[[84926  3769]
 [ 6075     0]]
(94770,)
(94770,)
roc_auc: 0.429955792925
log_loss: 0.938437371067
roc_auc for the hours: 0.358904109589
log_loss for the hours: 0.719710987239
saving predictions to csv file
hourspatient1_0_wideResNet1_10-12-12-43-42.csv
Accuracy validation for the hours:  0.923076923077
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [0]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.359990784
saving predictions to csv file
patient1_0_wideResNet1_10-12-12-47-59.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_1']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_1'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 12:48:02.015824
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_1']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [1]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.81938432
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 203.761627197 188.411010742
20 496.77197876 482.61751709
30 732.597296143 714.697686768
40 973.972167969 949.532727051
50 1245.81005859 1212.85552979
60 1576.76357422 1532.16108398
70 2013.54516602 1951.80438232
80 2668.75805664 2577.9690918
90 3942.10078125 3797.89812012
100 71591.0625 60304.03125
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.65824[0m     [32m0.66425[0m    0.99095      0.60618  74.30s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.62757[0m     0.67849    0.92494      0.49024  79.72s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.59524[0m     0.72337    0.82286      0.62317  77.19s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.54803[0m     0.75149    0.72925      0.56421  77.48s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.47953[0m     0.87632    0.54721      0.49404  78.70s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.40622[0m     0.88550    0.45875      0.57706  79.87s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.664253 at epoch 1.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.697224860188
Error rate (%):  30.2775139812
[[64633 24062]
 [ 4632  1443]]
(94770,)
(94770,)
roc_auc: 0.558724798095
log_loss: 0.636220323381
roc_auc for the hours: 0.556164383562
log_loss for the hours: 0.501939113575
saving predictions to csv file
hourspatient1_1_wideResNet1_10-12-13-09-36.csv
Accuracy validation for the hours:  0.74358974359
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [1]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.358860288
saving predictions to csv file
patient1_1_wideResNet1_10-12-13-13-57.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_2']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_2'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 13:13:59.820260
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_2']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [2]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.819585024
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 210.389639282 196.646928406
20 506.963934326 496.903918457
30 739.698999023 728.238903809
40 971.565100098 956.919091797
50 1226.64501953 1206.60388184
60 1529.57705078 1501.93178711
70 1919.78259277 1881.66341553
80 2487.38320313 2434.10976563
90 3554.0130127 3481.28129883
100 119907.929688 146484.890625
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.66926[0m     [32m0.68690[0m    0.97432      0.59723  73.94s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.63045[0m     0.69726    0.90418      0.60623  78.64s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.59904[0m     [32m0.64117[0m    0.93429      0.63538  77.25s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.56978[0m     0.71634    0.79541      0.60711  77.43s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.54882[0m     0.73454    0.74717      0.58040  77.45s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.51910[0m     0.73425    0.70698      0.64318  79.15s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      7     [36m0.48180[0m     0.81564    0.59070      0.62760  77.26s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      8     [36m0.43436[0m     0.90273    0.48116      0.57976  77.43s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.641169 at epoch 3.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.4356441912
Error rate (%):  56.43558088
[[37576 51119]
 [ 2365  3710]]
(94770,)
(94770,)
roc_auc: 0.513699517257
log_loss: inf
roc_auc for the hours: 0.515068493151
log_loss for the hours: 1.50704608539
saving predictions to csv file
hourspatient1_2_wideResNet1_10-12-13-39-10.csv
Accuracy validation for the hours:  0.397435897436
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [2]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.410699264
saving predictions to csv file
patient1_2_wideResNet1_10-12-13-43-35.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_3']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_3'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 13:43:38.120021
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_3']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [3]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.819712
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 19.1249866486 16.0321680069
20 110.960594177 117.977423096
30 462.367929077 465.247445679
40 726.516931152 722.714147949
50 983.638244629 972.796356201
60 1269.06445312 1248.00100098
70 1619.77319336 1586.1126709
80 2106.37036133 2054.18427734
90 2963.09577637 2880.79763184
100 141686.875 89649.6484375
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.70546[0m     [32m0.73781[0m    0.95615      0.50583  77.04s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.64781[0m     [32m0.73179[0m    0.88524      0.46477  77.43s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.63447[0m     0.73311    0.86545      0.44221  77.83s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.62734[0m     [32m0.69609[0m    0.90124      0.50149  78.17s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.60623[0m     0.79309    0.76440      0.48728  76.45s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.57178[0m     0.74884    0.76356      0.55628  75.40s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      7     [36m0.52952[0m     0.78089    0.67810      0.58844  76.11s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      8     [36m0.51071[0m     0.76325    0.66912      0.56999  75.73s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      9     [36m0.49712[0m     0.83528    0.59515      0.57042  75.52s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.696086 at epoch 4.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.87124617495
Error rate (%):  12.875382505
[[82568  6127]
 [ 6075     0]]
(94770,)
(94770,)
roc_auc: 0.414572411072
log_loss: 2.28846579545
roc_auc for the hours: 0.321917808219
log_loss for the hours: 2.27824310789
saving predictions to csv file
hourspatient1_3_wideResNet1_10-12-14-03-06.csv
Accuracy validation for the hours:  0.897435897436
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [3]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.359122432
saving predictions to csv file
patient1_3_wideResNet1_10-12-14-07-41.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_4']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_4'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 14:07:43.549473
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_4']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [4]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.81928192
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 235.407817078 219.809516907
20 571.790344238 556.848303223
30 840.501837158 821.775939941
40 1116.47878418 1091.31035156
50 1434.89074707 1400.26373291
60 1840.24331055 1790.55202637
70 2408.61494141 2333.43139648
80 3297.89345703 3176.70976563
90 4956.27602539 4739.19238281
100 52009.53125 38008.9335938
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.65789[0m     [32m0.71751[0m    0.91690      0.55384  76.77s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.64294[0m     [32m0.70542[0m    0.91143      0.60108  77.57s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.63091[0m     [32m0.64595[0m    0.97672      0.58817  77.03s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.62261[0m     [32m0.60153[0m    1.03505      0.67146  78.00s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.60444[0m     [32m0.60117[0m    1.00544      0.61857  77.62s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.58275[0m     0.65548    0.88903      0.59946  77.71s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      7     [36m0.55601[0m     0.77005    0.72204      0.49554  78.22s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      8     [36m0.51701[0m     0.95133    0.54346      0.50244  78.02s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      9     [36m0.46731[0m     2.27126    0.20575      0.49851  77.61s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     10     [36m0.42936[0m     0.75011    0.57240      0.60217  76.66s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.601172 at epoch 5.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.935897435897
Error rate (%):  6.41025641026
[[88695     0]
 [ 6075     0]]
(94770,)
(94770,)
roc_auc: 0.479638085574
log_loss: 2.227352856
roc_auc for the hours: 0.41095890411
log_loss for the hours: 2.22500276321
saving predictions to csv file
hourspatient1_4_wideResNet1_10-12-14-31-14.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [4]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.358368768
saving predictions to csv file
patient1_4_wideResNet1_10-12-14-36-07.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_5']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_5'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 14:36:09.667325
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_5']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [5]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.820383744
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 231.335012817 211.108001709
20 564.578271484 538.999780273
30 830.936474609 795.66987915
40 1104.11230469 1055.32932129
50 1420.78125 1352.56451416
60 1826.70258789 1730.86726074
70 2401.11716309 2262.68579102
80 3287.26503906 3085.56469727
90 4899.46132813 4571.94418945
100 55591.203125 52662.2460938
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.67715[0m     [32m0.65215[0m    1.03833      0.65690  74.55s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.65567[0m     0.66631    0.98404      0.55176  76.54s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.63051[0m     0.70308    0.89677      0.57651  78.13s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.59753[0m     0.68658    0.87029      0.58974  77.99s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.56223[0m     0.71048    0.79134      0.57553  78.14s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.52115[0m     0.84653    0.61563      0.56977  78.09s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.652151 at epoch 1.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.935897435897
Error rate (%):  6.41025641026
[[88695     0]
 [ 6075     0]]
(94770,)
(94770,)
roc_auc: 0.432652889857
log_loss: 1.15173926322
roc_auc for the hours: 0.352054794521
log_loss for the hours: 1.05408115275
saving predictions to csv file
hourspatient1_5_wideResNet1_10-12-14-55-20.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [5]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.359376384
saving predictions to csv file
patient1_5_wideResNet1_10-12-14-59-47.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_6']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_6'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 14:59:49.642357
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_6']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [6]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.818683904
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 199.270783997 178.304678345
20 484.265484619 454.425598145
30 715.207281494 673.034472656
40 957.550097656 897.335144043
50 1246.79968262 1160.86651611
60 1628.27236328 1502.71569824
70 2172.52145996 1989.60817871
80 3015.20869141 2745.85849609
90 4633.05883789 4178.59511719
100 66751.359375 59361.5703125
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.66923[0m     [32m0.66440[0m    1.00728      0.60808  73.89s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.63087[0m     0.71499    0.88235      0.55827  77.66s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.58575[0m     0.74523    0.78600      0.57895  78.43s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.54050[0m     0.97741    0.55300      0.49416  77.34s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.49006[0m     1.10015    0.44544      0.48890  77.06s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.42097[0m     1.21157    0.34746      0.47341  79.50s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.664398 at epoch 1.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.172132531392
Error rate (%):  82.7867468608
[[10238 78457]
 [    0  6075]]
(94770,)
(94770,)
roc_auc: 0.520138803691
log_loss: nan
roc_auc for the hours: 0.58904109589
log_loss for the hours: inf
saving predictions to csv file
hourspatient1_6_wideResNet1_10-12-15-22-30.csv
Accuracy validation for the hours:  0.153846153846
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [6]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.35774208
saving predictions to csv file
patient1_6_wideResNet1_10-12-15-26-49.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_7']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_7'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 15:26:51.074195
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_7']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [7]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.820355072
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 182.900706482 163.150218201
20 446.00692749 416.755505371
30 662.357696533 620.480499268
40 892.956396484 834.12010498
50 1172.0982666 1087.89544678
60 1542.81384277 1420.86425781
70 2076.69821777 1899.79864502
80 2929.02983398 2668.57714844
90 4619.13442383 4199.77285156
100 65353.1796875 57503.8945312
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.66117[0m     [32m0.65604[0m    1.00782      0.62680  75.46s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.61869[0m     [32m0.63064[0m    0.98105      0.64580  77.45s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.58591[0m     0.65686    0.89198      0.61720  76.96s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.56491[0m     [32m0.61345[0m    0.92086      0.68857  77.37s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.53555[0m     0.65259    0.82065      0.58798  77.33s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.50054[0m     0.76675    0.65281      0.63509  78.41s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      7     [36m0.46318[0m     0.77593    0.59693      0.64515  79.89s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      8     [36m0.43067[0m     0.67555    0.63751      0.68611  78.64s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      9     [36m0.38296[0m     0.85877    0.44594      0.65531  76.86s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.613455 at epoch 4.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.912124089902
Error rate (%):  8.78759100981
[[86426  2269]
 [ 6059    16]]
(94770,)
(94770,)
roc_auc: 0.511882193962
log_loss: 0.738454730877
roc_auc for the hours: 0.419178082192
log_loss for the hours: 0.578138154408
saving predictions to csv file
hourspatient1_7_wideResNet1_10-12-15-46-41.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [7]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.359798272
saving predictions to csv file
patient1_7_wideResNet1_10-12-15-51-30.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_8']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_8'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 15:51:32.415590
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_8']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [8]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.820146176
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 179.447947693 164.423493958
20 434.278393555 418.093994141
30 634.319030762 613.24385376
40 834.442565918 807.11171875
50 1056.00579834 1020.13357544
60 1321.37426758 1274.3189209
70 1666.15869141 1603.34324951
80 2169.84814453 2082.13676758
90 3113.30068359 2981.24484863
100 59862.1054688 57871.4179688
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.69715[0m     [32m1.79919[0m    0.38748      0.51804  75.67s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.66560[0m     [32m0.67781[0m    0.98199      0.55610  79.65s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.63617[0m     0.70243    0.90566      0.58980  79.04s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.61161[0m     0.68295    0.89554      0.51588  77.66s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.57409[0m     [32m0.63443[0m    0.90489      0.61099  77.78s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.54054[0m     0.71363    0.75745      0.53090  76.88s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      7     [36m0.49109[0m     1.55498    0.31582      0.54874  76.96s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      8     [36m0.45379[0m     0.84722    0.53562      0.57623  77.22s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      9     [36m0.39001[0m     0.98464    0.39610      0.58610  79.95s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     10     [36m0.34113[0m     1.19100    0.28642      0.58564  79.26s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.634427 at epoch 5.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.934747282895
Error rate (%):  6.52527171046
[[88586   109]
 [ 6075     0]]
(94770,)
(94770,)
roc_auc: 0.476661131909
log_loss: 0.56097015443
roc_auc for the hours: 0.408219178082
log_loss for the hours: 0.382320033495
saving predictions to csv file
hourspatient1_8_wideResNet1_10-12-16-14-48.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [8]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.358921728
saving predictions to csv file
patient1_8_wideResNet1_10-12-16-19-17.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_9']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_9'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 16:19:19.837077
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_9']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [9]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.82020352
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 3.68383948803 3.51945617199
20 8.91916770935 8.73870506287
30 13.5332503319 13.2244482994
40 19.6162849426 18.9431503296
50 42.7269630432 33.8711013794
60 446.623547363 383.009014893
70 778.942749023 709.81932373
80 1201.11340332 1105.85910645
90 1927.03088379 1777.32213135
100 43853.8789062 40357.3945312
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.73705[0m     [32m8.57960[0m    0.08591      0.50122  76.05s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.66865[0m     [32m1.34689[0m    0.49644      0.51626  78.87s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.57035[0m     [32m1.07163[0m    0.53223      0.51845  76.70s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.56601[0m     [32m0.99107[0m    0.57111      0.33967  76.96s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.56466[0m     1.04166    0.54208      0.49973  77.64s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.56302[0m     [32m0.98172[0m    0.57350      0.48583  79.57s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      7     [36m0.55756[0m     1.03947    0.53638      0.52363  79.25s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      8     [36m0.55739[0m     0.99180    0.56199      0.51845  78.40s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      9     [36m0.55212[0m     [32m0.91773[0m    0.60162      0.39470  78.52s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     10     [36m0.54414[0m     [32m0.84519[0m    0.64380      0.47832  78.75s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     11     [36m0.54091[0m     0.94399    0.57300      0.44621  78.50s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     12     0.54634     1.12151    0.48714      0.51756  78.32s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     13     [36m0.53465[0m     [32m0.81425[0m    0.65661      0.53299  78.20s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     14     [36m0.52922[0m     0.88665    0.59687      0.43113  77.72s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     15     [36m0.51808[0m     1.30276    0.39767      0.57672  78.84s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     16     [36m0.51739[0m     1.22441    0.42256      0.48838  78.26s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     17     [36m0.49883[0m     0.85972    0.58022      0.48746  78.23s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
     18     [36m0.48599[0m     1.79232    0.27115      0.50162  78.35s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.814252 at epoch 13.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.163596074707
Error rate (%):  83.6403925293
[[ 9429 79266]
 [    0  6075]]
(94770,)
(94770,)
roc_auc: 0.704191991003
log_loss: 1.83505432131
roc_auc for the hours: 0.780821917808
log_loss for the hours: 1.63227263105
saving predictions to csv file
hourspatient1_9_wideResNet1_10-12-16-59-24.csv
Accuracy validation for the hours:  0.153846153846
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [9]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.41197312
saving predictions to csv file
patient1_9_wideResNet1_10-12-17-03-44.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_10']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_10'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 17:03:46.462800
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_10']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [10]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.819478528
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 181.207902527 167.670619202
20 438.332196045 424.686590576
30 639.719543457 622.390942383
40 839.969042969 817.731738281
50 1060.19781494 1030.7331543
60 1320.43032227 1280.04846191
70 1650.03087158 1595.78609619
80 2111.48989258 2038.48054199
90 2911.55273438 2807.46408691
100 41643.4882812 36225.46875
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.64188[0m     [32m0.65518[0m    0.97970      0.57445  74.39s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.60516[0m     1.48884    0.40646      0.48997  76.61s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.59167[0m     0.85552    0.69159      0.49159  75.70s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.55287[0m     0.77332    0.71493      0.54385  80.40s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.49902[0m     0.88840    0.56170      0.49486  80.02s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.43406[0m     1.14862    0.37790      0.49906  79.25s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.655179 at epoch 1.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.110467447504
Error rate (%):  88.9532552496
[[ 4394 84301]
 [    0  6075]]
(94770,)
(94770,)
roc_auc: 0.55588815604
log_loss: nan
roc_auc for the hours: 0.63698630137
log_loss for the hours: nan
saving predictions to csv file
hourspatient1_10_wideResNet1_10-12-17-19-57.csv
Accuracy validation for the hours:  0.0897435897436
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [10]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.358225408
saving predictions to csv file
patient1_10_wideResNet1_10-12-17-24-17.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_11']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_11'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 17:24:19.586015
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_11']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [11]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.820011008
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 172.641601563 159.5427948
20 417.636303711 403.23772583
30 608.427856445 589.179815674
40 796.191516113 769.670605469
50 999.883514404 964.325683594
60 1236.0432373 1189.17692871
70 1532.10228271 1470.09255371
80 1945.44143066 1860.52646484
90 2669.32939453 2545.69404297
100 34311.5273438 30092.4199219
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.61728[0m     [32m0.60887[0m    1.01381      0.66748  76.04s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.57980[0m     0.69118    0.83885      0.63415  78.01s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.53597[0m     0.74665    0.71784      0.55073  77.08s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.49764[0m     0.97685    0.50943      0.50557  77.26s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.43699[0m     1.14302    0.38231      0.50027  78.70s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.37027[0m     1.52363    0.24302      0.45695  79.68s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.608872 at epoch 1.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.935897435897
Error rate (%):  6.41025641026
[[88695     0]
 [ 6075     0]]
(94770,)
(94770,)
roc_auc: 0.476114775354
log_loss: 2.22152289447
roc_auc for the hours: 0.383561643836
log_loss for the hours: 2.22095825845
saving predictions to csv file
hourspatient1_11_wideResNet1_10-12-17-43-50.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [11]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.358942208
saving predictions to csv file
patient1_11_wideResNet1_10-12-17-48-05.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_12']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_12'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 17:48:07.405593
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_12']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [12]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.81952768
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 194.413856506 178.851933289
20 463.675524902 446.537554932
30 666.165478516 644.010736084
40 859.942541504 831.373522949
50 1065.9508667 1029.34899902
60 1304.29125977 1256.71569824
70 1606.91943359 1543.18864746
80 2047.88012695 1958.46350098
90 2871.70686035 2742.33198242
100 68176.640625 59867.6914062
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.63710[0m     [32m0.60031[0m    1.06127      0.64822  76.70s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.62277[0m     0.60713    1.02576      0.64851  79.13s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.61328[0m     0.60848    1.00789      0.65355  78.85s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.59075[0m     0.66042    0.89450      0.62612  80.07s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.55095[0m     1.54871    0.35575      0.47049  78.74s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.51591[0m     1.02309    0.50426      0.46451  77.90s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.600312 at epoch 1.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.915870001055
Error rate (%):  8.41299989448
[[86797  1898]
 [ 6075     0]]
(94770,)
(94770,)
roc_auc: 0.478200575004
log_loss: 2.23320872458
roc_auc for the hours: 0.397260273973
log_loss for the hours: 2.228459981
saving predictions to csv file
hourspatient1_12_wideResNet1_10-12-18-06-34.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [12]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.35829504
saving predictions to csv file
patient1_12_wideResNet1_10-12-18-10-53.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_13']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_13'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 18:10:55.009491
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_13']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [13]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.819707904
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 197.41583252 182.761578369
20 473.741113281 459.648413086
30 683.193365479 665.443499756
40 884.565112305 862.165649414
50 1098.331604 1068.85339355
60 1343.71057129 1304.4578125
70 1651.5090332 1598.25623779
80 2090.38417969 2016.00366211
90 2902.72646484 2791.59272461
100 37327.25 36955.34375
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.62454[0m     [32m0.69230[0m    0.90213      0.61975  76.64s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.59029[0m     0.79417    0.74327      0.44119  76.72s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.55119[0m     1.85040    0.29787      0.49430  76.86s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.51852[0m     1.30965    0.39592      0.50882  77.77s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.47415[0m     1.00063    0.47385      0.51922  76.54s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.42920[0m     0.87860    0.48851      0.61997  79.16s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.692298 at epoch 1.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.935897435897
Error rate (%):  6.41025641026
[[88695     0]
 [ 6075     0]]
(94770,)
(94770,)
roc_auc: 0.450649610945
log_loss: 1.10815473415
roc_auc for the hours: 0.393150684932
log_loss for the hours: 1.00600423887
saving predictions to csv file
hourspatient1_13_wideResNet1_10-12-18-26-44.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [13]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.358450688
saving predictions to csv file
patient1_13_wideResNet1_10-12-18-31-05.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_14']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_14'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 18:31:07.117617
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_14']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [14]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.81944576
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 189.141261292 174.980825806
20 452.630731201 438.836401367
30 649.66987915 632.660009766
40 836.557116699 814.948742676
50 1031.56469727 1003.98742676
60 1251.25163574 1216.06953125
70 1519.30529785 1471.67954102
80 1885.33984375 1820.3204834
90 2516.96833496 2415.86462402
100 43412.1367188 33402.015625
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.62761[0m     [32m0.81945[0m    0.76589      0.56604  76.99s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.61191[0m     [32m0.67370[0m    0.90828      0.61978  75.19s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.59514[0m     0.84747    0.70226      0.57569  75.20s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.56657[0m     0.68016    0.83300      0.61716  75.87s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.51763[0m     0.77974    0.66385      0.61316  76.27s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.45643[0m     0.82519    0.55312      0.65317  76.09s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      7     [36m0.40340[0m     0.96729    0.41704      0.64056  73.93s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.673698 at epoch 2.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.915205233724
Error rate (%):  8.47947662762
[[86734  1961]
 [ 6075     0]]
(94770,)
(94770,)
roc_auc: 0.478200575004
log_loss: 2.2329128772
roc_auc for the hours: 0.397260273973
log_loss for the hours: 2.22849831211
saving predictions to csv file
hourspatient1_14_wideResNet1_10-12-18-50-27.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [14]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.358712832
saving predictions to csv file
patient1_14_wideResNet1_10-12-18-54-40.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config9.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_15']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config9.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_15'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-12 18:54:42.923450
Hostname: kat
gpu1
Configuration 'config9.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet1
evaluation:
    online_training: False
    model: wideResNet1

end Configuration
['patient1_15']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [15]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.82178048
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 192.412426758 176.768930054
20 459.689099121 442.431689453
30 658.81307373 637.209912109
40 846.730224609 819.873974609
50 1042.01245117 1009.00811768
60 1261.45869141 1219.99689941
70 1528.8362793 1476.44569092
80 1896.24025879 1829.35996094
90 2539.709375 2448.71398926
100 29197.0292969 29615.0136719
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  wideResNet1
Model name for the evaluation phase:  wideResNet1
Training model...
# Neural Network with 606338 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1  conv2d_1             64x192x64
  2  conv2d_2             64x192x64
  3  dropout1             64x192x64
  4  conv2d_3             64x96x32
  5  batch_norm1          64x96x32
  6  batch_norm1_nonlin   64x96x32
  7                       64x96x32
  8  res0__conv1          64x96x32
  9  res0__conv1_nonlin   64x96x32
 10  res0__dropout        64x96x32
 11  res0__conv2          64x96x32
 12  res0__projection     64x96x32
 13  res0__sum            64x96x32
 14  res3__bn             64x96x32
 15  res3__nonlin         64x96x32
 16                       64x48x16
 17  res3__conv1          64x48x16
 18  res3__conv1_nonlin   64x48x16
 19  res3__dropout        64x48x16
 20  res3__conv2          64x48x16
 21  res3__projection     64x48x16
 22  res3__sum            64x48x16
 23  res4_1_bn            64x48x16
 24  res4_1_nonlin        64x48x16
 25                       64x48x16
 26  res4_1_conv1         64x48x16
 27  res4_1_conv1_nonlin  64x48x16
 28  res4_1_dropout       64x48x16
 29  res4_1_conv2         64x48x16
 30  res4_1_sum           64x48x16
 31  res4_2_bn            64x48x16
 32  res4_2_nonlin        64x48x16
 33                       64x48x16
 34  res4_2_conv1         64x48x16
 35  res4_2_conv1_nonlin  64x48x16
 36  res4_2_dropout       64x48x16
 37  res4_2_conv2         64x48x16
 38  res4_2_sum           64x48x16
 39  res5__bn             64x48x16
 40  res5__nonlin         64x48x16
 41                       64x24x8
 42  res5__conv1          64x24x8
 43  res5__conv1_nonlin   64x24x8
 44  res5__dropout        64x24x8
 45  res5__conv2          64x24x8
 46  res5__projection     64x24x8
 47  res5__sum            64x24x8
 48  res6_1_bn            64x24x8
 49  res6_1_nonlin        64x24x8
 50                       64x24x8
 51  res6_1_conv1         64x24x8
 52  res6_1_conv1_nonlin  64x24x8
 53  res6_1_dropout       64x24x8
 54  res6_1_conv2         64x24x8
 55  res6_1_sum           64x24x8
 56  res6_2_bn            64x24x8
 57  res6_2_nonlin        64x24x8
 58                       64x24x8
 59  res6_2_conv1         64x24x8
 60  res6_2_conv1_nonlin  64x24x8
 61  res6_2_dropout       64x24x8
 62  res6_2_conv2         64x24x8
 63  res6_2_sum           64x24x8
 64  bn_post_conv         64x24x8
 65  post_conv_nonlin     64x24x8
 66  last_conv            2x24x8
 67  global_pool          2
 68  softmax              2

BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m0.62037[0m     [32m0.69204[0m    0.89644      0.60700  76.27s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      2     [36m0.60309[0m     [32m0.62391[0m    0.96663      0.66883  76.87s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      3     [36m0.58333[0m     0.75511    0.77252      0.57651  76.46s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      4     [36m0.55994[0m     [32m0.59205[0m    0.94577      0.66386  76.58s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      5     [36m0.51873[0m     0.65299    0.79440      0.63075  76.47s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      6     [36m0.47727[0m     0.71261    0.66974      0.61026  76.44s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      7     [36m0.42560[0m     0.78920    0.53928      0.59843  75.62s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      8     [36m0.36222[0m     1.76731    0.20495      0.56430  74.84s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
      9     [36m0.31048[0m     1.31214    0.23662      0.59394  74.98s
BI_train_bal_complete called with len(X) = 2336
BI_test_bal_complete called with len(X) = 584
Early stopping.
Best valid loss was 0.592045 at epoch 4.
Loaded parameters to layer 'conv2d_1' (shape 64x1x3x3).
Loaded parameters to layer 'conv2d_1' (shape 64).
Loaded parameters to layer 'conv2d_2' (shape 64x64x3x3).
Loaded parameters to layer 'conv2d_2' (shape 64).
Loaded parameters to layer 'conv2d_3' (shape 64x64x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn7' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn16' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn25' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn33' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn41' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn50' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn58' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
probabilities_normal (88695, 2)
probabilities_seizure (6075, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
Performance on relevant data
Accuracy validation:  0.935897435897
Error rate (%):  6.41025641026
[[88695     0]
 [ 6075     0]]
(94770,)
(94770,)
roc_auc: 0.483420711427
log_loss: 2.21840190966
roc_auc for the hours: 0.417808219178
log_loss for the hours: 2.21805291584
saving predictions to csv file
hourspatient1_15_wideResNet1_10-12-19-13-08.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [15]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.361211392
saving predictions to csv file
patient1_15_wideResNet1_10-12-19-17-41.csv
