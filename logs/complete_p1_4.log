['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_0']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_0'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 02:16:03.726716
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_0']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [0]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.786202624
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 199.036781311 184.038919067
20 483.221002197 465.519171143
30 718.880554199 694.377087402
40 969.482617188 933.868884277
50 1265.8637085 1213.74743652
60 1644.84228516 1568.92561035
70 2171.59033203 2061.92285156
80 2997.35341797 2842.94628906
90 4640.41015625 4440.24106445
100 101397.328125 96893.890625
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.59960[0m     [32m1.80124[0m    0.33288      0.40260  147.59s
      2     [36m0.52084[0m     2.48560    0.20954      0.43581  149.71s
      3     [36m0.46321[0m     [32m0.84859[0m    0.54586      0.53509  149.74s
      4     [36m0.40338[0m     0.98613    0.40905      0.59261  149.87s
      5     [36m0.33159[0m     1.00524    0.32986      0.62376  149.87s
      6     [36m0.28931[0m     2.61330    0.11071      0.48203  149.87s
      7     [36m0.23611[0m     2.58705    0.09127      0.45806  149.86s
      8     [36m0.18551[0m     1.28997    0.14381      0.59740  149.92s
Early stopping.
Best valid loss was 0.848585 at epoch 3.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.542191780822
Error rate (%):  45.7808219178
yVal [1 1 0 ..., 0 1 0]
[[1132  702]
 [ 969  847]]
roc_auc: 0.614051037909
log_loss 0.832454500671
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[  1.14880628e-07   1.00000000e+00]
[ 0.00230198  0.99769884]
[  8.51757824e-04   9.99148726e-01]
[ 0.00184621  0.99815571]
[  2.98916816e-13   1.00000000e+00]
roc_auc for the hours: 0.802739726027
log_loss for the hours nan
saving predictions to csv file
hourspatient1_0_wideResNet0_10-01-02-48-04.csv
Accuracy validation for the hours:  0.205128205128
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [0]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.362571264
saving predictions to csv file
patient1_0_wideResNet0_10-01-02-53-47.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_1']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_1'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 02:53:49.587220
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_1']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [1]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.732020736
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 203.761627197 188.411010742
20 496.77197876 482.61751709
30 732.597296143 714.697686768
40 973.972167969 949.532727051
50 1245.81005859 1212.85552979
60 1576.76357422 1532.16108398
70 2013.54516602 1951.80438232
80 2668.75805664 2577.9690918
90 3942.10078125 3797.89812012
100 71591.0625 60304.03125
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.64325[0m     [32m0.92721[0m    0.69374      0.60185  147.75s
      2     [36m0.59637[0m     [32m0.60919[0m    0.97896      0.67682  153.52s
      3     [36m0.57067[0m     0.96947    0.58864      0.61143  153.43s
      4     [36m0.49249[0m     1.99705    0.24661      0.51900  154.72s
      5     [36m0.40919[0m     1.18699    0.34473      0.50907  154.10s
      6     [36m0.32749[0m     1.50570    0.21750      0.55906  152.76s
      7     [36m0.29047[0m     2.49971    0.11620      0.50257  151.73s
Early stopping.
Best valid loss was 0.609190 at epoch 2.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.656438356164
Error rate (%):  34.3561643836
yVal [1 1 0 ..., 0 1 0]
[[ 803 1031]
 [ 223 1593]]
roc_auc: 0.715360013259
log_loss 0.612721264485
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[  1.00000000e+00   1.71367352e-16]
[  1.00000000e+00   1.99726779e-17]
[  1.00000000e+00   2.04417092e-18]
[  1.00000000e+00   5.32722229e-15]
[  1.00000000e+00   6.95954548e-22]
roc_auc for the hours: 0.383561643836
log_loss for the hours 2.20274332097
saving predictions to csv file
hourspatient1_1_wideResNet0_10-01-03-22-25.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [1]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.364135936
saving predictions to csv file
patient1_1_wideResNet0_10-01-03-28-22.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_2']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_2'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 03:28:24.876485
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_2']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [2]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.791875584
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 210.389639282 196.646928406
20 506.963934326 496.903918457
30 739.698999023 728.238903809
40 971.565100098 956.919091797
50 1226.64501953 1206.60388184
60 1529.57705078 1501.93178711
70 1919.78259277 1881.66341553
80 2487.38320313 2434.10976563
90 3554.0130127 3481.28129883
100 119907.929688 146484.890625
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.63237[0m     [32m0.85829[0m    0.73678      0.61623  151.86s
      2     [36m0.57672[0m     [32m0.83411[0m    0.69141      0.47552  154.32s
      3     [36m0.52456[0m     2.27895    0.23018      0.48340  154.33s
      4     [36m0.42643[0m     1.21162    0.35195      0.51181  152.59s
      5     [36m0.35972[0m     1.04511    0.34419      0.57754  151.40s
      6     [36m0.28853[0m     2.46669    0.11697      0.48956  151.05s
      7     [36m0.25019[0m     2.80715    0.08913      0.44060  153.25s
Early stopping.
Best valid loss was 0.834112 at epoch 2.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.476438356164
Error rate (%):  52.3561643836
yVal [1 1 0 ..., 0 1 0]
[[1651  183]
 [1728   88]]
roc_auc: 0.567594212837
log_loss 0.834281213798
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
roc_auc for the hours: 0.417808219178
log_loss for the hours 2.22237579772
saving predictions to csv file
hourspatient1_2_wideResNet0_10-01-04-00-31.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [2]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.365241856
saving predictions to csv file
patient1_2_wideResNet0_10-01-04-06-46.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_3']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_3'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 04:06:48.077239
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_3']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [3]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.792137728
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 19.1249866486 16.0321680069
20 110.960594177 117.977423096
30 462.367929077 465.247445679
40 726.516931152 722.714147949
50 983.638244629 972.796356201
60 1269.06445312 1248.00100098
70 1619.77319336 1586.1126709
80 2106.37036133 2054.18427734
90 2963.09577637 2880.79763184
100 141686.875 89649.6484375
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.60795[0m     [32m0.78763[0m    0.77187      0.49127  151.40s
      2     [36m0.58536[0m     [32m0.72709[0m    0.80508      0.54365  152.33s
      3     [36m0.56842[0m     1.10599    0.51394      0.51592  152.67s
      4     [36m0.53971[0m     1.26305    0.42731      0.51181  154.35s
      5     [36m0.50752[0m     1.26490    0.40124      0.45122  153.22s
      6     [36m0.47237[0m    11.54521    0.04092      0.47004  151.57s
      7     [36m0.44475[0m     1.00019    0.44467      0.52619  153.03s
Early stopping.
Best valid loss was 0.727089 at epoch 2.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.542191780822
Error rate (%):  45.7808219178
yVal [1 1 0 ..., 0 1 0]
[[ 228 1606]
 [  65 1751]]
roc_auc: 0.634316496044
log_loss 0.728304329619
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
roc_auc for the hours: 0.349315068493
log_loss for the hours 2.30294602159
saving predictions to csv file
hourspatient1_3_wideResNet0_10-01-04-39-15.csv
Accuracy validation for the hours:  0.884615384615
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [3]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.36595456
saving predictions to csv file
patient1_3_wideResNet0_10-01-04-45-16.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_4']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_4'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 04:45:18.963662
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_4']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [4]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.791220224
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 235.407817078 219.809516907
20 571.790344238 556.848303223
30 840.501837158 821.775939941
40 1116.47878418 1091.31035156
50 1434.89074707 1400.26373291
60 1840.24331055 1790.55202637
70 2408.61494141 2333.43139648
80 3297.89345703 3176.70976563
90 4956.27602539 4739.19238281
100 52009.53125 38008.9335938
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.62729[0m     [32m0.98231[0m    0.63859      0.45806  150.36s
      2     [36m0.60997[0m     1.28145    0.47600      0.46183  152.76s
      3     [36m0.57450[0m     5.49355    0.10458      0.49949  152.01s
      4     [36m0.51690[0m     1.90772    0.27095      0.51215  150.46s
      5     [36m0.43999[0m     1.33136    0.33048      0.52893  149.79s
      6     [36m0.37987[0m     1.93624    0.19619      0.46354  149.78s
Early stopping.
Best valid loss was 0.982313 at epoch 1.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.46602739726
Error rate (%):  53.397260274
yVal [1 1 0 ..., 0 1 0]
[[1237  597]
 [1352  464]]
roc_auc: 0.419758754125
log_loss 1.00213341118
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
roc_auc for the hours: 0.417808219178
log_loss for the hours 2.2257748535
saving predictions to csv file
hourspatient1_4_wideResNet0_10-01-05-22-27.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [4]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.37039872
saving predictions to csv file
patient1_4_wideResNet0_10-01-05-28-47.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_5']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_5'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 05:28:49.170648
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_5']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [5]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.79204352
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 231.335012817 211.108001709
20 564.578271484 538.999780273
30 830.936474609 795.66987915
40 1104.11230469 1055.32932129
50 1420.78125 1352.56451416
60 1826.70258789 1730.86726074
70 2401.11716309 2262.68579102
80 3287.26503906 3085.56469727
90 4899.46132813 4571.94418945
100 55591.203125 52662.2460938
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.65868[0m     [32m0.67145[0m    0.98099      0.55460  146.86s
      2     [36m0.58131[0m     0.76737    0.75754      0.57994  149.75s
      3     [36m0.51453[0m     0.79519    0.64706      0.55734  152.30s
      4     [36m0.46227[0m     1.23705    0.37369      0.51969  153.65s
      5     [36m0.41194[0m     1.14550    0.35962      0.51421  153.70s
      6     [36m0.35835[0m     1.18486    0.30244      0.50394  150.79s
Early stopping.
Best valid loss was 0.671447 at epoch 1.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.563287671233
Error rate (%):  43.6712328767
yVal [1 1 0 ..., 0 1 0]
[[ 930  904]
 [ 690 1126]]
roc_auc: 0.600984403749
log_loss 0.666911542605
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[  1.00000000e+00   9.80908925e-45]
[  1.00000000e+00   1.62684102e-34]
[  1.00000000e+00   2.24316653e-30]
[  1.00000000e+00   2.67230431e-22]
[  1.00000000e+00   1.39694910e-36]
roc_auc for the hours: 0.390410958904
log_loss for the hours 2.22721373202
saving predictions to csv file
hourspatient1_5_wideResNet0_10-01-06-06-13.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [5]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.312137216
saving predictions to csv file
patient1_5_wideResNet0_10-01-06-11-59.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_6']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_6'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 06:12:01.823277
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_6']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [6]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.792211456
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 199.270783997 178.304678345
20 484.265484619 454.425598145
30 715.207281494 673.034472656
40 957.550097656 897.335144043
50 1246.79968262 1160.86651611
60 1628.27236328 1502.71569824
70 2172.52145996 1989.60817871
80 3015.20869141 2745.85849609
90 4633.05883789 4178.59511719
100 66751.359375 59361.5703125
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.65251[0m     [32m0.71589[0m    0.91147      0.51489  146.85s
      2     [36m0.57275[0m     1.56409    0.36619      0.48511  150.16s
      3     [36m0.50980[0m     1.26189    0.40400      0.46354  150.30s
      4     [36m0.46908[0m     1.15464    0.40626      0.51695  152.88s
      5     [36m0.40407[0m     0.86765    0.46571      0.59637  153.01s
      6     [36m0.35470[0m     1.01171    0.35060      0.55769  150.84s
Early stopping.
Best valid loss was 0.715890 at epoch 1.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.49698630137
Error rate (%):  50.301369863
yVal [1 1 0 ..., 0 1 0]
[[ 514 1320]
 [ 516 1300]]
roc_auc: 0.468445094855
log_loss 0.72227601717
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 0.10302198  0.8969776 ]
[  2.10146085e-04   9.99791741e-01]
[  1.45717440e-05   9.99985516e-01]
[  6.33733316e-06   9.99999881e-01]
[ 0.03083966  0.9691599 ]
roc_auc for the hours: 0.583561643836
log_loss for the hours inf
saving predictions to csv file
hourspatient1_6_wideResNet0_10-01-06-40-51.csv
Accuracy validation for the hours:  0.179487179487
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [6]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.312391168
saving predictions to csv file
patient1_6_wideResNet0_10-01-06-46-38.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_7']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_7'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 06:46:39.822822
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_7']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [7]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.791093248
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 182.900706482 163.150218201
20 446.00692749 416.755505371
30 662.357696533 620.480499268
40 892.956396484 834.12010498
50 1172.0982666 1087.89544678
60 1542.81384277 1420.86425781
70 2076.69821777 1899.79864502
80 2929.02983398 2668.57714844
90 4619.13442383 4199.77285156
100 65353.1796875 57503.8945312
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.65027[0m     [32m0.66579[0m    0.97669      0.48237  147.32s
      2     [36m0.55585[0m     [32m0.57905[0m    0.95993      0.76036  150.45s
      3     [36m0.47903[0m     0.65407    0.73238      0.65697  152.96s
      4     [36m0.40450[0m     1.01122    0.40001      0.50976  154.32s
      5     [36m0.33083[0m     0.79037    0.41858      0.71893  154.46s
      6     [36m0.28518[0m     1.20737    0.23620      0.60938  152.03s
      7     [36m0.22641[0m     1.25893    0.17984      0.63882  150.56s
Early stopping.
Best valid loss was 0.579053 at epoch 2.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.756164383562
Error rate (%):  24.3835616438
yVal [1 1 0 ..., 0 1 0]
[[1215  619]
 [ 271 1545]]
roc_auc: 0.805345312958
log_loss 0.566526686965
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[  1.00000000e+00   1.28107659e-20]
[  1.00000000e+00   1.24664827e-16]
[  1.00000000e+00   6.60013366e-16]
[  1.00000000e+00   4.20798482e-18]
[  1.00000000e+00   2.44205992e-21]
roc_auc for the hours: 0.390410958904
log_loss for the hours 2.22465825547
saving predictions to csv file
hourspatient1_7_wideResNet0_10-01-07-14-19.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [7]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.363456
saving predictions to csv file
patient1_7_wideResNet0_10-01-07-20-09.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_8']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_8'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 07:20:11.640482
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_8']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [8]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.791805952
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 179.447947693 164.423493958
20 434.278393555 418.093994141
30 634.319030762 613.24385376
40 834.442565918 807.11171875
50 1056.00579834 1020.13357544
60 1321.37426758 1274.3189209
70 1666.15869141 1603.34324951
80 2169.84814453 2082.13676758
90 3113.30068359 2981.24484863
100 59862.1054688 57871.4179688
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.65157[0m     [32m0.73948[0m    0.88112      0.43786  151.12s
      2     [36m0.57607[0m     1.09369    0.52672      0.47860  150.98s
      3     [36m0.47785[0m     2.11335    0.22611      0.46662  151.01s
      4     [36m0.39535[0m     1.66931    0.23684      0.46868  153.84s
      5     [36m0.30534[0m     1.73297    0.17619      0.49743  152.96s
      6     [36m0.25246[0m     2.51524    0.10037      0.49024  150.71s
Early stopping.
Best valid loss was 0.739479 at epoch 1.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.435890410959
Error rate (%):  56.4109589041
yVal [1 1 0 ..., 0 1 0]
[[1302  532]
 [1527  289]]
roc_auc: 0.503303064004
log_loss 0.735411542453
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[  9.99957502e-01   4.58243230e-05]
[  9.99907255e-01   9.63680723e-05]
[  9.99906659e-01   9.32613839e-05]
[  9.99728620e-01   2.72011443e-04]
[  9.99512732e-01   4.87477897e-04]
roc_auc for the hours: 0.402739726027
log_loss for the hours 0.58430490292
saving predictions to csv file
hourspatient1_8_wideResNet0_10-01-07-45-23.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [8]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.371201536
saving predictions to csv file
patient1_8_wideResNet0_10-01-07-51-07.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_9']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_9'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 07:51:09.427374
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_9']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [9]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.79151104
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 3.68383948803 3.51945617199
20 8.91916770935 8.73870506287
30 13.5332503319 13.2244482994
40 19.6162849426 18.9431503296
50 42.7269630432 33.8711013794
60 446.623547363 383.009014893
70 778.942749023 709.81932373
80 1201.11340332 1105.85910645
90 1927.03088379 1777.32213135
100 43853.8789062 40357.3945312
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.67591[0m     [32m0.92196[0m    0.73313      0.47415  146.74s
      2     [36m0.66453[0m     [32m0.82196[0m    0.80848      0.44985  149.53s
      3     [36m0.65462[0m     1.39247    0.47011      0.45840  149.58s
      4     [36m0.62869[0m     1.10635    0.56825      0.46936  149.71s
      5     [36m0.59496[0m     [32m0.76355[0m    0.77920      0.51215  149.70s
      6     [36m0.54763[0m     1.10429    0.49592      0.47347  149.73s
      7     [36m0.50632[0m     1.99545    0.25374      0.46594  149.80s
      8     [36m0.48680[0m     1.09032    0.44647      0.48442  149.81s
      9     [36m0.44463[0m     1.75921    0.25275      0.44437  149.50s
     10     [36m0.42452[0m     1.64116    0.25867      0.48887  149.50s
Early stopping.
Best valid loss was 0.763546 at epoch 5.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.498904109589
Error rate (%):  50.1095890411
yVal [1 1 0 ..., 0 1 0]
[[ 264 1570]
 [ 259 1557]]
roc_auc: 0.613438825609
log_loss 0.764960013427
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 1.  0.]
[ 0.50688851  0.49311146]
[ 0.50408328  0.49591678]
[  1.00000000e+00   1.12103877e-44]
[ 1.  0.]
roc_auc for the hours: 0.438356164384
log_loss for the hours 1.67311010512
saving predictions to csv file
hourspatient1_9_wideResNet0_10-01-08-26-00.csv
Accuracy validation for the hours:  0.820512820513
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [9]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.369591808
saving predictions to csv file
patient1_9_wideResNet0_10-01-08-31-41.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_10']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_10'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 08:31:43.973715
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_10']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [10]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.791703552
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 181.207902527 167.670619202
20 438.332196045 424.686590576
30 639.719543457 622.390942383
40 839.969042969 817.731738281
50 1060.19781494 1030.7331543
60 1320.43032227 1280.04846191
70 1650.03087158 1595.78609619
80 2111.48989258 2038.48054199
90 2911.55273438 2807.46408691
100 41643.4882812 36225.46875
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.62952[0m     [32m0.81336[0m    0.77397      0.51250  146.45s
      2     [36m0.55785[0m     1.34489    0.41480      0.50736  149.22s
      3     [36m0.47912[0m     0.90505    0.52939      0.55529  149.65s
      4     [36m0.41210[0m     2.71935    0.15154      0.49024  149.75s
      5     [36m0.34538[0m     1.19737    0.28845      0.50154  149.81s
      6     [36m0.26585[0m     1.69600    0.15675      0.47655  149.77s
Early stopping.
Best valid loss was 0.813363 at epoch 1.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.521917808219
Error rate (%):  47.8082191781
yVal [1 1 0 ..., 0 1 0]
[[957 877]
 [868 948]]
roc_auc: 0.53350623802
log_loss 0.798094115089
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[  1.00000000e+00   2.86703579e-20]
[  1.00000000e+00   1.57917167e-22]
[  1.00000000e+00   1.98431057e-22]
[  1.00000000e+00   1.77610117e-16]
[  1.00000000e+00   2.87469889e-28]
roc_auc for the hours: 0.376712328767
log_loss for the hours 2.22048060584
saving predictions to csv file
hourspatient1_10_wideResNet0_10-01-08-56-33.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [10]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.370906624
saving predictions to csv file
patient1_10_wideResNet0_10-01-09-02-13.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_11']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_11'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 09:02:16.089630
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_11']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [11]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.791986176
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 172.641601563 159.5427948
20 417.636303711 403.23772583
30 608.427856445 589.179815674
40 796.191516113 769.670605469
50 999.883514404 964.325683594
60 1236.0432373 1189.17692871
70 1532.10228271 1470.09255371
80 1945.44143066 1860.52646484
90 2669.32939453 2545.69404297
100 34311.5273438 30092.4199219
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.58677[0m     [32m0.82085[0m    0.71484      0.53851  146.04s
      2     [36m0.50712[0m     [32m0.78801[0m    0.64354      0.60664  149.47s
      3     [36m0.43459[0m     1.91861    0.22651      0.46114  149.57s
      4     [36m0.34945[0m     2.31488    0.15096      0.45190  149.65s
      5     [36m0.28365[0m     1.20634    0.23513      0.53714  149.68s
      6     [36m0.22493[0m     2.66696    0.08434      0.45567  149.70s
      7     [36m0.17407[0m     3.57418    0.04870      0.45943  149.82s
Early stopping.
Best valid loss was 0.788009 at epoch 2.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.611506849315
Error rate (%):  38.8493150685
yVal [1 1 0 ..., 0 1 0]
[[ 753 1081]
 [ 337 1479]]
roc_auc: 0.619052022733
log_loss 0.78406746198
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[  1.00000000e+00   4.20389539e-45]
[  1.00000000e+00   7.29656110e-42]
[  1.00000000e+00   1.89175293e-43]
[  1.00000000e+00   1.07361308e-32]
[ 1.  0.]
roc_auc for the hours: 0.417808219178
log_loss for the hours 2.22053246792
saving predictions to csv file
hourspatient1_11_wideResNet0_10-01-09-29-35.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [11]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.366269952
saving predictions to csv file
patient1_11_wideResNet0_10-01-09-35-18.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_12']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_12'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 09:35:20.533776
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_12']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [12]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.791216128
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 194.413856506 178.851933289
20 463.675524902 446.537554932
30 666.165478516 644.010736084
40 859.942541504 831.373522949
50 1065.9508667 1029.34899902
60 1304.29125977 1256.71569824
70 1606.91943359 1543.18864746
80 2047.88012695 1958.46350098
90 2871.70686035 2742.33198242
100 68176.640625 59867.6914062
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.60603[0m     [32m0.78819[0m    0.76888      0.55974  146.11s
      2     [36m0.56778[0m     2.05505    0.27628      0.48785  149.18s
      3     [36m0.53298[0m     0.84582    0.63013      0.61349  149.57s
      4     [36m0.47714[0m     2.20427    0.21646      0.48168  149.67s
      5     [36m0.41516[0m     1.12923    0.36765      0.52105  149.70s
      6     [36m0.36131[0m     0.99445    0.36332      0.62170  149.80s
Early stopping.
Best valid loss was 0.788194 at epoch 1.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.562739726027
Error rate (%):  43.7260273973
yVal [1 1 0 ..., 0 1 0]
[[ 238 1596]
 [   0 1816]]
roc_auc: 0.780918972997
log_loss 0.788279818946
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[  1.00000000e+00   2.66102962e-08]
[  1.00000000e+00   1.01816857e-08]
[  1.00000000e+00   3.17743911e-08]
[  1.00000000e+00   1.04234772e-07]
[  1.00000000e+00   2.60784461e-08]
roc_auc for the hours: 0.297260273973
log_loss for the hours 1.12300948062
saving predictions to csv file
hourspatient1_12_wideResNet0_10-01-10-00-10.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [12]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.370624
saving predictions to csv file
patient1_12_wideResNet0_10-01-10-05-52.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_13']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_13'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 10:05:54.254781
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_13']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [13]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.792059904
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 197.41583252 182.761578369
20 473.741113281 459.648413086
30 683.193365479 665.443499756
40 884.565112305 862.165649414
50 1098.331604 1068.85339355
60 1343.71057129 1304.4578125
70 1651.5090332 1598.25623779
80 2090.38417969 2016.00366211
90 2902.72646484 2791.59272461
100 37327.25 36955.34375
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.59416[0m     [32m0.80467[0m    0.73839      0.56111  146.11s
      2     [36m0.54400[0m     1.36636    0.39814      0.54536  149.55s
      3     [36m0.49762[0m     1.65301    0.30104      0.49298  149.60s
      4     [36m0.41414[0m     1.03278    0.40099      0.48545  149.69s
      5     [36m0.32638[0m     1.09618    0.29775      0.53406  149.71s
      6     [36m0.26238[0m     2.70152    0.09712      0.52037  149.78s
Early stopping.
Best valid loss was 0.804672 at epoch 1.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.560273972603
Error rate (%):  43.9726027397
yVal [1 1 0 ..., 0 1 0]
[[ 229 1605]
 [   0 1816]]
roc_auc: 0.618147665967
log_loss 0.800181580812
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 0.99635816  0.00364102]
[ 0.93432528  0.06567572]
[ 0.75235444  0.24764618]
[ 0.62809575  0.37190428]
[ 0.98155844  0.01844267]
roc_auc for the hours: 0.345205479452
log_loss for the hours 0.536855426845
saving predictions to csv file
hourspatient1_13_wideResNet0_10-01-10-30-43.csv
Accuracy validation for the hours:  0.730769230769
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [13]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.312292864
saving predictions to csv file
patient1_13_wideResNet0_10-01-10-36-24.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_14']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_14'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 10:36:27.023151
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_14']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [14]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.79136768
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 189.141261292 174.980825806
20 452.630731201 438.836401367
30 649.66987915 632.660009766
40 836.557116699 814.948742676
50 1031.56469727 1003.98742676
60 1251.25163574 1216.06953125
70 1519.30529785 1471.67954102
80 1885.33984375 1820.3204834
90 2516.96833496 2415.86462402
100 43412.1367188 33402.015625
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.59175[0m     [32m0.68236[0m    0.86721      0.61315  146.14s
      2     [36m0.53419[0m     1.07401    0.49738      0.65115  149.61s
      3     [36m0.47022[0m     1.19218    0.39442      0.46662  149.67s
      4     [36m0.37406[0m     1.44882    0.25818      0.51352  149.75s
      5     [36m0.29831[0m     1.72666    0.17277      0.53406  149.77s
      6     [36m0.25364[0m     2.73528    0.09273      0.51866  149.89s
Early stopping.
Best valid loss was 0.682362 at epoch 1.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.60904109589
Error rate (%):  39.095890411
yVal [1 1 0 ..., 0 1 0]
[[ 407 1427]
 [   0 1816]]
roc_auc: 0.768946304267
log_loss 0.68893194323
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[  1.00000000e+00   9.79473748e-16]
[  1.00000000e+00   2.21819433e-17]
[  1.00000000e+00   3.14813347e-16]
[  1.00000000e+00   1.22720473e-15]
[  1.00000000e+00   5.61511831e-18]
roc_auc for the hours: 0.383561643836
log_loss for the hours 2.22396456423
saving predictions to csv file
hourspatient1_14_wideResNet0_10-01-11-01-16.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [14]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.311653888
saving predictions to csv file
patient1_14_wideResNet0_10-01-11-06-59.csv
['python', 'train_batch.py', '--debug-sub-ratio=1', '--model-filename=run3.pickle', '--config-filename=config1.yml', '--no-channels=1', '--target-gpu=gpu3', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_15']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config1.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_filename='run3.pickle', no_channels=1, no_preprocessing=False, no_save_model=False, no_save_preprocessed=False, no_training=False, patients=['patient1_15'], plot_prob_dist=False, shift=0, shuffle_before_split=True, target_gpu='gpu3')
Git reference:  Timestamp: 2016-10-01 11:07:01.549437
Hostname: kat
gpu3
Configuration 'config1.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: wideResNet0
evaluation:
    online_training: False
    model: wideResNet0

end Configuration
['patient1_15']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [15]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.79187968
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 192.412426758 176.768930054
20 459.689099121 442.431689453
30 658.81307373 637.209912109
40 846.730224609 819.873974609
50 1042.01245117 1009.00811768
60 1261.45869141 1219.99689941
70 1528.8362793 1476.44569092
80 1896.24025879 1829.35996094
90 2539.709375 2448.71398926
100 29197.0292969 29615.0136719
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
size 18250
no_normal 365
no_seizure 25
no_samples_normal_ph 25
no_samples_seizure_ph 365
Histogram:
[9125 9125]
magnitudes.shape (18250,)
labels.shape (18250,)
Ratio validation: 0.2
xVal.shape (3650,)
yVal.shape (3650,)
xTrain.shape (14600,)
yTrain.shape (14600,)
xVal.shape (3650, 2)
yVal.shape (3650,)
Saving preprocessed data...
Building models ...
Model name for the training phase:  wideResNet0
Model name for the evaluation phase:  wideResNet0
Training model...
# Neural Network with 532482 learnable parameters

## Layer information

  #  name                 size
---  -------------------  ---------
  0  input                1x192x64
  1                       64x192x64
  2  batch_norm1          64x192x64
  3  batch_norm1_nonlin   64x192x64
  4                       64x192x64
  5  res0__conv1          64x192x64
  6  res0__conv1_nonlin   64x192x64
  7  res0__dropout        64x192x64
  8  res0__conv2          64x192x64
  9  res0__projection     64x192x64
 10  res0__sum            64x192x64
 11  res3__bn             64x192x64
 12  res3__nonlin         64x192x64
 13                       64x96x32
 14  res3__conv1          64x96x32
 15  res3__conv1_nonlin   64x96x32
 16  res3__dropout        64x96x32
 17  res3__conv2          64x96x32
 18  res3__projection     64x96x32
 19  res3__sum            64x96x32
 20  res4_1_bn            64x96x32
 21  res4_1_nonlin        64x96x32
 22                       64x96x32
 23  res4_1_conv1         64x96x32
 24  res4_1_conv1_nonlin  64x96x32
 25  res4_1_dropout       64x96x32
 26  res4_1_conv2         64x96x32
 27  res4_1_sum           64x96x32
 28  res4_2_bn            64x96x32
 29  res4_2_nonlin        64x96x32
 30                       64x96x32
 31  res4_2_conv1         64x96x32
 32  res4_2_conv1_nonlin  64x96x32
 33  res4_2_dropout       64x96x32
 34  res4_2_conv2         64x96x32
 35  res4_2_sum           64x96x32
 36  res5__bn             64x96x32
 37  res5__nonlin         64x96x32
 38                       64x48x16
 39  res5__conv1          64x48x16
 40  res5__conv1_nonlin   64x48x16
 41  res5__dropout        64x48x16
 42  res5__conv2          64x48x16
 43  res5__projection     64x48x16
 44  res5__sum            64x48x16
 45  res6_1_bn            64x48x16
 46  res6_1_nonlin        64x48x16
 47                       64x48x16
 48  res6_1_conv1         64x48x16
 49  res6_1_conv1_nonlin  64x48x16
 50  res6_1_dropout       64x48x16
 51  res6_1_conv2         64x48x16
 52  res6_1_sum           64x48x16
 53  res6_2_bn            64x48x16
 54  res6_2_nonlin        64x48x16
 55                       64x48x16
 56  res6_2_conv1         64x48x16
 57  res6_2_conv1_nonlin  64x48x16
 58  res6_2_dropout       64x48x16
 59  res6_2_conv2         64x48x16
 60  res6_2_sum           64x48x16
 61  bn_post_conv         64x48x16
 62  post_conv_nonlin     64x48x16
 63  last_conv            2x48x16
 64  global_pool          2
 65  softmax              2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -------
      1     [36m0.59025[0m     [32m1.30182[0m    0.45340      0.48990  146.37s
      2     [36m0.56432[0m     [32m0.63933[0m    0.88267      0.65389  149.57s
      3     [36m0.53524[0m     0.68459    0.78183      0.59192  149.69s
      4     [36m0.49526[0m     0.91740    0.53985      0.53338  149.77s
      5     [36m0.42879[0m     0.94499    0.45375      0.60630  149.80s
      6     [36m0.36226[0m     3.11566    0.11627      0.51558  149.88s
      7     [36m0.34189[0m     1.13886    0.30021      0.52996  149.97s
Early stopping.
Best valid loss was 0.639332 at epoch 2.
Loaded parameters to layer 'conv2ddnn1' (shape 64x1x3x3).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'batch_norm1' (shape 64).
Loaded parameters to layer 'conv2ddnn4' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv1' (shape 64).
Loaded parameters to layer 'res0__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res0__conv2' (shape 64).
Loaded parameters to layer 'res0__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'res3__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn13' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv1' (shape 64).
Loaded parameters to layer 'res3__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res3__conv2' (shape 64).
Loaded parameters to layer 'res3__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'res4_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn22' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv1' (shape 64).
Loaded parameters to layer 'res4_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_1_conv2' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'res4_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn30' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv1' (shape 64).
Loaded parameters to layer 'res4_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res4_2_conv2' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'res5__bn' (shape 64).
Loaded parameters to layer 'conv2ddnn38' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv1' (shape 64).
Loaded parameters to layer 'res5__conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res5__conv2' (shape 64).
Loaded parameters to layer 'res5__projection' (shape 64x64x1x1).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'res6_1_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn47' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv1' (shape 64).
Loaded parameters to layer 'res6_1_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_1_conv2' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'res6_2_bn' (shape 64).
Loaded parameters to layer 'conv2ddnn55' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv1' (shape 64).
Loaded parameters to layer 'res6_2_conv2' (shape 64x64x3x3).
Loaded parameters to layer 'res6_2_conv2' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'bn_post_conv' (shape 64).
Loaded parameters to layer 'last_conv' (shape 2x64x3x3).
Loaded parameters to layer 'last_conv' (shape 2).
Saving model...
Validating...
probabilities.shape (3650, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0]
Ground Truth:
[0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0]
Performance on relevant data
Accuracy validation:  0.647123287671
Error rate (%):  35.2876712329
yVal [1 1 0 ..., 0 1 0]
[[ 708 1126]
 [ 162 1654]]
roc_auc: 0.716461935347
log_loss 0.639182417125
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
[ 1.  0.]
roc_auc for the hours: 0.424657534247
log_loss for the hours 2.22257472257
saving predictions to csv file
hourspatient1_15_wideResNet0_10-01-11-34-21.csv
Accuracy validation for the hours:  0.935897435897
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [15]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.365086208
saving predictions to csv file
patient1_15_wideResNet0_10-01-11-40-05.csv
