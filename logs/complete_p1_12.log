['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_0']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_0'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 16:48:53.664690
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_0']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [0]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.81000448
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 199.036781311 184.038919067
20 483.221002197 465.519171143
30 718.880554199 694.377087402
40 969.482617188 933.868884277
50 1265.8637085 1213.74743652
60 1644.84228516 1568.92561035
70 2171.59033203 2061.92285156
80 2997.35341797 2842.94628906
90 4640.41015625 4440.24106445
100 101397.328125 96893.890625
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m21.11187[0m     [32m0.73548[0m   28.70494      0.52397  6.89s
      2     [36m1.08897[0m     [32m0.72873[0m    1.49434      0.48801  6.92s
      3     [36m0.72624[0m     [32m0.70378[0m    1.03191      0.50685  6.76s
      4     [36m0.67256[0m     0.72961    0.92181      0.40068  6.70s
      5     [36m0.67027[0m     0.75921    0.88285      0.40240  6.82s
      6     [36m0.66678[0m     0.78514    0.84925      0.44863  6.88s
      7     [36m0.66175[0m     0.75765    0.87342      0.41096  6.78s
      8     0.66430     0.78621    0.84494      0.44178  6.88s
      9     [36m0.65783[0m     0.74119    0.88753      0.40411  7.00s
     10     0.66649     0.77949    0.85502      0.44007  7.09s
     11     [36m0.64700[0m     0.77315    0.83684      0.43493  7.21s
     12     [36m0.64516[0m     0.76155    0.84717      0.39555  7.45s
     13     0.64883     0.77981    0.83204      0.42295  11.60s
Early stopping.
Best valid loss was 0.703778 at epoch 3.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.505936073059
Error rate (%):  49.4063926941
[[713 382]
 [700 395]]
roc_auc: 0.517363691333
log_loss: 0.715004667041
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 0.28241113  0.7175889 ]
[ 0.88706315  0.11293691]
[ 0.96714681  0.03285345]
[ 0.93954563  0.06045443]
[ 0.22833468  0.77166498]
roc_auc for the hours: 0.484931506849
log_loss for the hours: 0.912883978131
saving predictions to csv file
hourspatient1_0_net12_10-04-16-58-51.csv
Accuracy validation for the hours:  0.679487179487
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [0]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.101361152
saving predictions to csv file
patient1_0_net12_10-04-17-02-55.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_1']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_1'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 17:02:56.640756
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_1']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [1]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.809189376
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 203.761627197 188.411010742
20 496.77197876 482.61751709
30 732.597296143 714.697686768
40 973.972167969 949.532727051
50 1245.81005859 1212.85552979
60 1576.76357422 1532.16108398
70 2013.54516602 1951.80438232
80 2668.75805664 2577.9690918
90 3942.10078125 3797.89812012
100 71591.0625 60304.03125
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m23.08010[0m     [32m4.07523[0m    5.66351      0.48973  7.07s
      2     [36m1.53327[0m     [32m0.86234[0m    1.77804      0.48459  10.65s
      3     [36m0.75278[0m     [32m0.70397[0m    1.06934      0.48116  10.86s
      4     [36m0.69897[0m     [32m0.70025[0m    0.99817      0.47432  10.90s
      5     [36m0.68299[0m     0.71393    0.95666      0.48288  11.19s
      6     [36m0.67937[0m     [32m0.69560[0m    0.97666      0.48288  10.99s
      7     [36m0.67506[0m     [32m0.68653[0m    0.98330      0.47603  11.65s
      8     [36m0.67401[0m     [32m0.67404[0m    0.99996      0.46575  11.85s
      9     [36m0.66975[0m     [32m0.67285[0m    0.99539      0.44007  11.76s
     10     0.67302     [32m0.67177[0m    1.00186      0.45890  11.86s
     11     [36m0.66582[0m     [32m0.67120[0m    0.99197      0.45205  8.36s
     12     [36m0.66526[0m     [32m0.66805[0m    0.99581      0.45890  13.05s
     13     0.66752     0.67513    0.98873      0.44863  13.07s
     14     0.66755     0.66815    0.99911      0.43151  11.50s
     15     [36m0.66189[0m     [32m0.66277[0m    0.99867      0.47432  7.42s
     16     0.66584     0.67063    0.99286      0.46747  7.51s
     17     [36m0.65566[0m     0.68004    0.96415      0.45719  7.36s
     18     [36m0.65519[0m     0.66434    0.98623      0.48288  7.46s
     19     0.65805     0.68791    0.95659      0.46575  7.44s
     20     [36m0.65166[0m     0.69626    0.93595      0.44863  7.52s
     21     [36m0.65031[0m     0.67502    0.96340      0.44863  7.33s
     22     [36m0.64849[0m     0.68813    0.94239      0.43322  7.38s
     23     [36m0.64845[0m     0.68390    0.94817      0.47260  7.40s
     24     [36m0.64561[0m     0.69589    0.92775      0.43836  7.49s
     25     0.65214     0.70037    0.93114      0.41952  7.37s
Early stopping.
Best valid loss was 0.662772 at epoch 15.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.448401826484
Error rate (%):  55.1598173516
[[558 537]
 [671 424]]
roc_auc: 0.500726006547
log_loss: 0.67649515036
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 0.31478655  0.68521333]
[ 0.75579774  0.24420185]
[ 0.61290318  0.38709679]
[ 0.7145716   0.28542882]
[ 0.57692939  0.42307064]
roc_auc for the hours: 0.47397260274
log_loss for the hours: 0.698477281982
saving predictions to csv file
hourspatient1_1_net12_10-04-17-20-20.csv
Accuracy validation for the hours:  0.641025641026
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [1]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.105371136
saving predictions to csv file
patient1_1_net12_10-04-17-24-17.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_2']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_2'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 17:24:18.305749
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_2']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [2]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.810545152
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 210.389639282 196.646928406
20 506.963934326 496.903918457
30 739.698999023 728.238903809
40 971.565100098 956.919091797
50 1226.64501953 1206.60388184
60 1529.57705078 1501.93178711
70 1919.78259277 1881.66341553
80 2487.38320313 2434.10976563
90 3554.0130127 3481.28129883
100 119907.929688 146484.890625
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1    [36m27.01087[0m     [32m2.84668[0m    9.48854      0.50000  10.31s
      2     [36m1.32531[0m     [32m0.81180[0m    1.63257      0.48630  12.93s
      3     [36m0.71332[0m     [32m0.70023[0m    1.01870      0.54795  12.97s
      4     [36m0.68959[0m     [32m0.69492[0m    0.99233      0.45548  8.89s
      5     [36m0.67690[0m     0.69688    0.97134      0.42979  7.39s
      6     [36m0.67393[0m     [32m0.68849[0m    0.97884      0.43151  7.54s
      7     [36m0.67172[0m     0.69620    0.96483      0.40925  7.33s
      8     [36m0.66710[0m     0.69158    0.96460      0.43836  7.32s
      9     0.66713     0.69228    0.96367      0.44178  7.24s
     10     [36m0.66546[0m     0.69016    0.96421      0.43322  7.35s
     11     [36m0.66512[0m     0.69021    0.96366      0.44692  7.44s
     12     [36m0.66351[0m     [32m0.68325[0m    0.97111      0.45377  7.44s
     13     0.66592     0.68823    0.96758      0.45034  7.50s
     14     0.66808     0.68522    0.97498      0.44007  7.49s
     15     0.66394     [32m0.68312[0m    0.97193      0.46062  7.38s
     16     0.66786     0.68649    0.97286      0.45719  7.49s
     17     [36m0.65607[0m     0.69787    0.94010      0.43664  7.49s
     18     [36m0.65522[0m     0.68497    0.95656      0.48801  7.50s
     19     0.65847     0.70113    0.93915      0.42466  7.55s
     20     [36m0.65315[0m     0.69384    0.94135      0.45548  7.38s
     21     0.65778     0.69958    0.94025      0.42979  7.37s
     22     [36m0.65185[0m     0.68909    0.94597      0.44007  7.40s
     23     [36m0.64697[0m     0.68821    0.94008      0.47089  7.45s
     24     0.65115     0.70029    0.92983      0.42808  7.42s
     25     0.65095     0.69426    0.93761      0.44349  7.50s
Early stopping.
Best valid loss was 0.683116 at epoch 15.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.43698630137
Error rate (%):  56.301369863
[[479 616]
 [617 478]]
roc_auc: 0.439992493901
log_loss: 0.701773402595
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 0.61294967  0.38705003]
[ 0.16211469  0.83788502]
[ 0.53915495  0.46084508]
[ 0.65408152  0.34591892]
[ 0.68968117  0.31031841]
roc_auc for the hours: 0.452054794521
log_loss for the hours: 1.07091318563
saving predictions to csv file
hourspatient1_2_net12_10-04-17-41-51.csv
Accuracy validation for the hours:  0.474358974359
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [2]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.10247936
saving predictions to csv file
patient1_2_net12_10-04-17-46-05.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_3']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_3'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 17:46:06.097416
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_3']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [3]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.810426368
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 19.1249866486 16.0321680069
20 110.960594177 117.977423096
30 462.367929077 465.247445679
40 726.516931152 722.714147949
50 983.638244629 972.796356201
60 1269.06445312 1248.00100098
70 1619.77319336 1586.1126709
80 2106.37036133 2054.18427734
90 2963.09577637 2880.79763184
100 141686.875 89649.6484375
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1    [36m20.85047[0m     [32m2.81416[0m    7.40914      0.49144  10.65s
      2     [36m0.97679[0m     [32m1.00485[0m    0.97208      0.47260  7.46s
      3     [36m0.68173[0m     [32m0.78241[0m    0.87132      0.42466  7.47s
      4     [36m0.67977[0m     0.88131    0.77131      0.40582  7.41s
      5     [36m0.66102[0m     0.90314    0.73192      0.41267  7.41s
      6     [36m0.65988[0m     0.95589    0.69034      0.41952  7.61s
      7     [36m0.65776[0m     0.94260    0.69782      0.40925  7.49s
      8     0.66424     0.92514    0.71799      0.41096  7.38s
      9     [36m0.65723[0m     0.87858    0.74805      0.40068  7.47s
     10     0.66629     0.87995    0.75719      0.41610  7.37s
     11     [36m0.65177[0m     0.87595    0.74407      0.41267  7.34s
     12     [36m0.65093[0m     0.89125    0.73035      0.40240  7.42s
     13     [36m0.64953[0m     0.88955    0.73017      0.40240  7.30s
Early stopping.
Best valid loss was 0.782414 at epoch 3.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.413242009132
Error rate (%):  58.6757990868
[[ 905  190]
 [1095    0]]
roc_auc: 0.344637934989
log_loss: 0.786717471766
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 0.97839838  0.02160131]
[ 0.9678703   0.03212876]
[ 0.97722632  0.02277358]
[ 0.99883282  0.0011667 ]
[  9.99060035e-01   9.40074038e-04]
roc_auc for the hours: 0.27397260274
log_loss for the hours: 0.482487391784
saving predictions to csv file
hourspatient1_3_net12_10-04-18-00-17.csv
Accuracy validation for the hours:  0.833333333333
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [3]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.103007744
saving predictions to csv file
patient1_3_net12_10-04-18-04-16.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_4']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_4'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 18:04:17.996618
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_4']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [4]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.810205184
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 235.407817078 219.809516907
20 571.790344238 556.848303223
30 840.501837158 821.775939941
40 1116.47878418 1091.31035156
50 1434.89074707 1400.26373291
60 1840.24331055 1790.55202637
70 2408.61494141 2333.43139648
80 3297.89345703 3176.70976563
90 4956.27602539 4739.19238281
100 52009.53125 38008.9335938
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1    [36m24.24680[0m     [32m1.42518[0m   17.01321      0.50000  10.93s
      2     [36m1.76694[0m     [32m0.71060[0m    2.48653      0.50000  10.96s
      3     [36m0.79155[0m     0.73510    1.07680      0.50000  11.56s
      4     [36m0.71011[0m     [32m0.68902[0m    1.03062      0.50000  10.05s
      5     [36m0.68842[0m     0.70007    0.98335      0.50000  10.35s
      6     0.69112     0.69708    0.99144      0.50171  13.01s
      7     [36m0.68460[0m     0.71145    0.96227      0.50000  13.11s
      8     0.68615     0.71572    0.95868      0.50171  9.18s
      9     0.68566     0.73606    0.93153      0.50000  7.43s
     10     0.68578     0.75922    0.90328      0.50000  7.44s
     11     0.68543     0.76640    0.89436      0.50000  7.41s
     12     0.68629     0.76391    0.89839      0.50171  7.39s
     13     0.68600     0.77185    0.88878      0.50171  7.52s
     14     [36m0.68344[0m     0.76853    0.88929      0.50685  7.43s
Early stopping.
Best valid loss was 0.689016 at epoch 4.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.502739726027
Error rate (%):  49.7260273973
[[   6 1089]
 [   0 1095]]
roc_auc: 0.655176080565
log_loss: 0.691300626569
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 0.08349478  0.91650468]
[ 0.10171352  0.89828682]
[ 0.12858884  0.87141103]
[ 0.1259345   0.87406516]
[ 0.126882    0.87311763]
roc_auc for the hours: 0.808219178082
log_loss for the hours: 1.7442783571
saving predictions to csv file
hourspatient1_4_net12_10-04-18-18-21.csv
Accuracy validation for the hours:  0.0641025641026
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [4]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.102753792
saving predictions to csv file
patient1_4_net12_10-04-18-22-26.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_5']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_5'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 18:22:27.778245
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_5']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [5]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.810397696
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 231.335012817 211.108001709
20 564.578271484 538.999780273
30 830.936474609 795.66987915
40 1104.11230469 1055.32932129
50 1420.78125 1352.56451416
60 1826.70258789 1730.86726074
70 2401.11716309 2262.68579102
80 3287.26503906 3085.56469727
90 4899.46132813 4571.94418945
100 55591.203125 52662.2460938
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m37.96561[0m     [32m1.63725[0m   23.18871      0.48973  7.15s
      2     [36m1.63893[0m     [32m0.76731[0m    2.13593      0.50000  7.07s
      3     [36m0.82560[0m     [32m0.68707[0m    1.20162      0.53253  7.12s
      4     [36m0.69906[0m     [32m0.68516[0m    1.02029      0.52226  7.22s
      5     [36m0.69464[0m     0.68959    1.00732      0.51370  7.13s
      6     [36m0.69162[0m     [32m0.68224[0m    1.01375      0.52397  7.14s
      7     [36m0.68683[0m     0.68465    1.00318      0.51370  7.34s
      8     0.68714     0.68386    1.00479      0.51541  7.39s
      9     0.68955     0.69560    0.99130      0.50514  7.37s
     10     0.68868     0.68817    1.00075      0.51199  7.19s
     11     0.69243     [32m0.68102[0m    1.01675      0.51541  7.13s
     12     [36m0.68410[0m     0.68155    1.00374      0.51370  7.19s
     13     [36m0.68277[0m     0.68646    0.99462      0.51712  7.19s
     14     0.68339     0.68775    0.99367      0.51541  7.33s
     15     0.68355     0.70171    0.97412      0.50685  7.41s
     16     0.68469     0.69377    0.98691      0.50514  10.01s
     17     [36m0.67797[0m     [32m0.67685[0m    1.00165      0.53253  9.94s
     18     [36m0.67716[0m     0.68598    0.98714      0.52740  10.06s
     19     [36m0.67280[0m     0.67980    0.98971      0.54281  9.96s
     20     [36m0.66769[0m     0.68915    0.96885      0.53767  10.03s
     21     0.66954     0.69322    0.96584      0.52568  10.09s
     22     0.66772     0.71674    0.93161      0.52397  8.05s
     23     0.67352     0.70827    0.95094      0.51712  7.23s
     24     0.67122     0.70793    0.94815      0.52397  7.28s
     25     [36m0.66408[0m     0.71164    0.93316      0.52740  7.30s
     26     [36m0.65607[0m     0.70453    0.93121      0.55308  7.37s
     27     0.65896     0.73078    0.90172      0.52740  7.36s
Early stopping.
Best valid loss was 0.676853 at epoch 17.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.527853881279
Error rate (%):  47.2146118721
[[ 110  985]
 [  49 1046]]
roc_auc: 0.68081524572
log_loss: 0.682513535866
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 0.03991885  0.96008062]
[ 0.03900857  0.96099126]
[ 0.24041216  0.75958753]
[ 0.15762837  0.84237188]
[ 0.31259274  0.68740714]
roc_auc for the hours: 0.72602739726
log_loss for the hours: 1.38936580737
saving predictions to csv file
hourspatient1_5_net12_10-04-18-38-46.csv
Accuracy validation for the hours:  0.192307692308
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [5]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.10206976
saving predictions to csv file
patient1_5_net12_10-04-18-42-44.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_6']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_6'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 18:42:46.258419
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_6']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [6]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.809549824
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 199.270783997 178.304678345
20 484.265484619 454.425598145
30 715.207281494 673.034472656
40 957.550097656 897.335144043
50 1246.79968262 1160.86651611
60 1628.27236328 1502.71569824
70 2172.52145996 1989.60817871
80 3015.20869141 2745.85849609
90 4633.05883789 4178.59511719
100 66751.359375 59361.5703125
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m30.92506[0m     [32m0.72542[0m   42.63058      0.50000  7.91s
      2     [36m1.06739[0m     1.06071    1.00630      0.48630  7.32s
      3     [36m0.70210[0m     [32m0.70969[0m    0.98930      0.48459  7.20s
      4     0.71956     [32m0.67977[0m    1.05853      0.47432  7.13s
      5     [36m0.69714[0m     0.68103    1.02365      0.50342  7.14s
      6     [36m0.69222[0m     0.68065    1.01700      0.61986  7.13s
      7     [36m0.69050[0m     0.68381    1.00979      0.58562  7.22s
      8     0.69180     0.68047    1.01665      0.59589  7.28s
      9     [36m0.68458[0m     0.69001    0.99214      0.54110  7.36s
     10     0.69206     0.68116    1.01600      0.59247  7.31s
     11     0.68828     [32m0.67504[0m    1.01963      0.53596  7.33s
     12     [36m0.67785[0m     0.67737    1.00071      0.58733  7.35s
     13     0.68284     [32m0.67501[0m    1.01159      0.60959  7.31s
     14     0.67811     [32m0.67331[0m    1.00713      0.61473  7.28s
     15     [36m0.67471[0m     0.67869    0.99414      0.58048  7.37s
     16     0.67757     0.67404    1.00524      0.59932  7.40s
     17     [36m0.67148[0m     0.67365    0.99678      0.45205  7.28s
     18     [36m0.66291[0m     [32m0.67267[0m    0.98550      0.62671  7.34s
     19     0.67286     [32m0.66641[0m    1.00969      0.52055  7.38s
     20     [36m0.65857[0m     [32m0.66168[0m    0.99531      0.51370  7.18s
     21     [36m0.65664[0m     0.66642    0.98533      0.62842  7.29s
     22     0.66392     [32m0.65933[0m    1.00697      0.60616  7.31s
     23     [36m0.65533[0m     [32m0.65879[0m    0.99475      0.46575  7.27s
     24     0.65679     0.65928    0.99622      0.44521  7.28s
     25     [36m0.65159[0m     [32m0.64911[0m    1.00381      0.57705  9.39s
     26     [36m0.64380[0m     [32m0.64217[0m    1.00254      0.59932  9.96s
     27     0.65789     0.66871    0.98383      0.46747  9.94s
     28     0.64908     0.68726    0.94444      0.47603  9.98s
     29     [36m0.64036[0m     0.65689    0.97484      0.51884  9.92s
     30     0.64914     0.69642    0.93212      0.47774  9.93s
     31     0.64497     0.74688    0.86356      0.47945  8.86s
     32     [36m0.62439[0m     0.67977    0.91853      0.48630  7.33s
     33     0.66022     0.64538    1.02299      0.62500  7.28s
     34     0.66320     0.69813    0.94996      0.48459  7.24s
     35     0.65065     0.66315    0.98114      0.48801  7.39s
     36     0.63297     0.64733    0.97782      0.55993  7.22s
Early stopping.
Best valid loss was 0.642169 at epoch 26.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.603652968037
Error rate (%):  39.6347031963
[[524 571]
 [297 798]]
roc_auc: 0.592194908363
log_loss: 0.651967945858
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 0.83440059  0.16559905]
[ 0.71466058  0.28533959]
[ 0.74697971  0.25301996]
[ 0.75804639  0.24195446]
[ 0.81908602  0.180914  ]
roc_auc for the hours: 0.572602739726
log_loss for the hours: 0.320259627274
saving predictions to csv file
hourspatient1_6_net12_10-04-18-55-42.csv
Accuracy validation for the hours:  0.910256410256
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [6]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.103200256
saving predictions to csv file
patient1_6_net12_10-04-18-59-46.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_7']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_7'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 18:59:47.981279
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_7']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [7]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.811298816
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 182.900706482 163.150218201
20 446.00692749 416.755505371
30 662.357696533 620.480499268
40 892.956396484 834.12010498
50 1172.0982666 1087.89544678
60 1542.81384277 1420.86425781
70 2076.69821777 1899.79864502
80 2929.02983398 2668.57714844
90 4619.13442383 4199.77285156
100 65353.1796875 57503.8945312
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m30.92937[0m     [32m0.68858[0m   44.91757      0.46575  9.50s
      2     [36m1.07877[0m     1.07532    1.00321      0.48630  10.09s
      3     [36m0.70855[0m     0.70961    0.99850      0.48801  9.99s
      4     0.71742     0.69912    1.02617      0.47945  10.06s
      5     [36m0.69647[0m     0.69854    0.99704      0.48288  10.01s
      6     [36m0.68960[0m     [32m0.68612[0m    1.00507      0.47432  10.17s
      7     0.69022     0.68886    1.00198      0.48116  8.56s
      8     0.69050     0.68729    1.00467      0.46404  7.23s
      9     [36m0.68275[0m     0.68910    0.99078      0.42123  7.31s
     10     0.68853     [32m0.68225[0m    1.00921      0.46233  7.29s
     11     0.68307     [32m0.67909[0m    1.00585      0.47945  7.31s
     12     [36m0.67095[0m     [32m0.67743[0m    0.99044      0.44521  7.18s
     13     0.67367     [32m0.67571[0m    0.99698      0.53596  7.20s
     14     0.67363     [32m0.67330[0m    1.00048      0.45377  7.24s
     15     [36m0.66535[0m     [32m0.66982[0m    0.99332      0.49315  7.30s
     16     [36m0.66528[0m     0.67606    0.98406      0.44521  7.25s
     17     [36m0.65416[0m     0.67341    0.97141      0.45377  7.34s
     18     [36m0.64914[0m     [32m0.66336[0m    0.97858      0.47260  7.29s
     19     0.64961     0.67233    0.96620      0.48459  7.31s
     20     [36m0.63889[0m     0.67120    0.95186      0.48288  7.32s
     21     [36m0.63042[0m     [32m0.65907[0m    0.95654      0.50342  7.34s
     22     0.64064     0.67121    0.95445      0.48630  7.33s
     23     [36m0.62518[0m     0.66586    0.93891      0.50342  7.17s
     24     [36m0.62217[0m     0.66944    0.92938      0.51884  7.14s
     25     0.62290     0.66833    0.93202      0.51884  7.14s
     26     [36m0.60852[0m     [32m0.62748[0m    0.96979      0.56849  7.13s
     27     0.62796     0.68842    0.91217      0.50856  7.14s
     28     0.61101     0.65235    0.93663      0.52740  7.16s
     29     0.61476     0.65537    0.93804      0.53082  7.16s
     30     [36m0.60797[0m     0.70061    0.86778      0.50000  7.14s
     31     [36m0.59505[0m     0.66997    0.88818      0.51884  7.14s
     32     0.60977     0.69646    0.87553      0.52055  7.15s
     33     0.60542     0.65633    0.92242      0.55137  7.14s
     34     0.61153     0.65385    0.93528      0.54110  7.15s
     35     0.59585     0.67952    0.87687      0.54452  7.13s
     36     [36m0.59295[0m     0.68351    0.86752      0.51884  7.14s
Early stopping.
Best valid loss was 0.627482 at epoch 26.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 0 0]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.527853881279
Error rate (%):  47.2146118721
[[765 330]
 [704 391]]
roc_auc: 0.634178603449
log_loss: 0.64940895668
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
[ 0.95998508  0.04001471]
[ 0.41010043  0.58989984]
[ 0.87059772  0.12940295]
[ 0.9507876   0.04921265]
[ 0.83272421  0.16727661]
roc_auc for the hours: 0.580821917808
log_loss for the hours: 0.30164097079
saving predictions to csv file
hourspatient1_7_net12_10-04-19-10-20.csv
Accuracy validation for the hours:  0.910256410256
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [7]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.103376384
saving predictions to csv file
patient1_7_net12_10-04-19-15-09.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_8']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_8'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 19:15:10.386140
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_8']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [8]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.810131456
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 179.447947693 164.423493958
20 434.278393555 418.093994141
30 634.319030762 613.24385376
40 834.442565918 807.11171875
50 1056.00579834 1020.13357544
60 1321.37426758 1274.3189209
70 1666.15869141 1603.34324951
80 2169.84814453 2082.13676758
90 3113.30068359 2981.24484863
100 59862.1054688 57871.4179688
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m22.81104[0m     [32m0.70968[0m   32.14288      0.49144  7.30s
      2     [36m0.86794[0m     0.99051    0.87626      0.48459  7.30s
      3     [36m0.68748[0m     [32m0.70281[0m    0.97818      0.47089  7.28s
      4     0.71773     [32m0.66022[0m    1.08711      0.55651  7.32s
      5     [36m0.66963[0m     [32m0.65603[0m    1.02073      0.56507  7.21s
      6     [36m0.66338[0m     [32m0.65403[0m    1.01429      0.56678  7.29s
      7     [36m0.66101[0m     0.65743    1.00545      0.55993  7.40s
      8     [36m0.65975[0m     [32m0.65162[0m    1.01248      0.57705  7.42s
      9     0.66096     [32m0.64794[0m    1.02010      0.58904  7.33s
     10     [36m0.65619[0m     0.65121    1.00765      0.58219  7.41s
     11     [36m0.65396[0m     0.64901    1.00763      0.60274  7.41s
     12     0.65397     [32m0.64485[0m    1.01414      0.57534  7.31s
     13     [36m0.65240[0m     0.64749    1.00759      0.60103  7.37s
     14     0.65483     [32m0.64204[0m    1.01993      0.61130  7.37s
     15     [36m0.64733[0m     0.64287    1.00694      0.59932  7.31s
     16     0.65644     0.65341    1.00465      0.57021  7.35s
     17     [36m0.64659[0m     0.65945    0.98049      0.52397  7.26s
     18     [36m0.64075[0m     0.64651    0.99108      0.57877  7.35s
     19     0.64867     0.66381    0.97720      0.52226  7.40s
     20     [36m0.63948[0m     0.66683    0.95898      0.48459  7.31s
     21     0.64453     0.65389    0.98569      0.54966  7.33s
     22     [36m0.63882[0m     0.65754    0.97152      0.55479  7.26s
     23     0.64649     0.66400    0.97363      0.49315  7.34s
     24     [36m0.63556[0m     0.66928    0.94962      0.46404  7.41s
Early stopping.
Best valid loss was 0.642036 at epoch 14.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.578538812785
Error rate (%):  42.1461187215
[[325 770]
 [153 942]]
roc_auc: 0.594190279602
log_loss: 0.656969994408
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
roc_auc for the hours: 0.619178082192
log_loss for the hours: 1.11196473003
saving predictions to csv file
hourspatient1_8_net12_10-04-19-24-56.csv
Accuracy validation for the hours:  0.448717948718
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [8]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.102626816
saving predictions to csv file
patient1_8_net12_10-04-19-28-44.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_9']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_9'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 19:28:45.797853
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_9']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [9]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.81031168
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 3.68383948803 3.51945617199
20 8.91916770935 8.73870506287
30 13.5332503319 13.2244482994
40 19.6162849426 18.9431503296
50 42.7269630432 33.8711013794
60 446.623547363 383.009014893
70 778.942749023 709.81932373
80 1201.11340332 1105.85910645
90 1927.03088379 1777.32213135
100 43853.8789062 40357.3945312
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1     [36m5.91752[0m     [32m0.91716[0m    6.45202      0.50000  7.43s
      2     [36m0.75637[0m     [32m0.73228[0m    1.03289      0.44521  7.47s
      3     [36m0.69817[0m     [32m0.70443[0m    0.99112      0.43322  7.50s
      4     [36m0.68833[0m     0.70835    0.97174      0.43151  7.39s
      5     0.68992     [32m0.69790[0m    0.98857      0.43664  7.37s
      6     [36m0.68733[0m     0.71237    0.96486      0.44007  7.39s
      7     [36m0.68687[0m     0.70292    0.97717      0.44007  7.43s
      8     [36m0.68362[0m     0.70715    0.96672      0.43493  7.41s
      9     0.68509     0.71080    0.96383      0.42808  7.44s
     10     0.68611     0.71769    0.95599      0.44521  7.51s
     11     0.68407     0.71791    0.95286      0.43836  7.31s
     12     [36m0.68237[0m     0.71891    0.94918      0.44007  7.32s
     13     0.68457     0.71455    0.95804      0.44007  7.36s
     14     0.68267     0.71821    0.95052      0.43322  7.26s
     15     0.68338     0.71777    0.95208      0.44863  7.25s
Early stopping.
Best valid loss was 0.697897 at epoch 5.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
xVal.shape (2190, 2)
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.43698630137
Error rate (%):  56.301369863
[[487 608]
 [625 470]]
roc_auc: 0.442292279143
log_loss: 0.696697060708
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
roc_auc for the hours: 0.430136986301
log_loss for the hours: 0.519443753581
saving predictions to csv file
hourspatient1_9_net12_10-04-19-37-46.csv
Accuracy validation for the hours:  0.538461538462
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [9]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.105477632
saving predictions to csv file
patient1_9_net12_10-04-19-41-33.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_10']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_10'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 19:41:34.242013
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_10']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [10]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.810545152
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 181.207902527 167.670619202
20 438.332196045 424.686590576
30 639.719543457 622.390942383
40 839.969042969 817.731738281
50 1060.19781494 1030.7331543
60 1320.43032227 1280.04846191
70 1650.03087158 1595.78609619
80 2111.48989258 2038.48054199
90 2911.55273438 2807.46408691
100 41643.4882812 36225.46875
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m10.70022[0m     [32m0.98979[0m   10.81055      0.52226  7.51s
      2     [36m0.70837[0m     1.39403    0.50814      0.50000  7.61s
      3     0.73339     [32m0.84184[0m    0.87117      0.52055  7.54s
      4     0.73881     0.86252    0.85657      0.51370  7.45s
      5     0.76811     [32m0.68452[0m    1.12212      0.54452  7.43s
      6     [36m0.68453[0m     0.77015    0.88882      0.52740  7.47s
      7     [36m0.67974[0m     0.70375    0.96588      0.53767  7.34s
      8     [36m0.67565[0m     0.69706    0.96929      0.54110  7.41s
      9     [36m0.66530[0m     0.72183    0.92169      0.54452  7.47s
     10     0.67567     0.71138    0.94980      0.54966  7.32s
     11     0.66950     0.71281    0.93924      0.54623  7.42s
     12     [36m0.66437[0m     0.71623    0.92759      0.55137  7.32s
     13     0.66643     0.72102    0.92429      0.54795  7.39s
     14     0.67032     0.71298    0.94017      0.55308  7.21s
     15     0.66721     0.71632    0.93145      0.55822  7.28s
Early stopping.
Best valid loss was 0.684518 at epoch 5.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
xVal.shape (2190, 2)
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.54200913242
Error rate (%):  45.799086758
[[  92 1003]
 [   0 1095]]
roc_auc: 0.583055816184
log_loss: 0.689152275523
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
roc_auc for the hours: 0.616438356164
log_loss for the hours: 2.10562485465
saving predictions to csv file
hourspatient1_10_net12_10-04-19-49-41.csv
Accuracy validation for the hours:  0.153846153846
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [10]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.10313472
saving predictions to csv file
patient1_10_net12_10-04-19-53-51.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_11']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_11'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 19:53:52.183701
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_11']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [11]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.809467904
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 172.641601563 159.5427948
20 417.636303711 403.23772583
30 608.427856445 589.179815674
40 796.191516113 769.670605469
50 999.883514404 964.325683594
60 1236.0432373 1189.17692871
70 1532.10228271 1470.09255371
80 1945.44143066 1860.52646484
90 2669.32939453 2545.69404297
100 34311.5273438 30092.4199219
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m14.41983[0m     [32m1.05504[0m   13.66751      0.50000  7.40s
      2     [36m1.08283[0m     [32m0.79104[0m    1.36886      0.50000  7.44s
      3     [36m0.73270[0m     [32m0.68723[0m    1.06617      0.54281  7.47s
      4     [36m0.68095[0m     0.70311    0.96849      0.52740  7.39s
      5     [36m0.67650[0m     0.70179    0.96395      0.53082  7.39s
      6     [36m0.67326[0m     0.70059    0.96099      0.54281  7.46s
      7     [36m0.66479[0m     0.71279    0.93265      0.53253  7.40s
      8     [36m0.66123[0m     0.71963    0.91884      0.54110  7.43s
      9     [36m0.65530[0m     0.72957    0.89820      0.53938  7.33s
     10     [36m0.65342[0m     0.74771    0.87390      0.54452  7.39s
     11     [36m0.65093[0m     0.76567    0.85014      0.54795  7.30s
     12     [36m0.64418[0m     0.77733    0.82871      0.54623  7.37s
     13     0.64650     0.79141    0.81689      0.54281  7.27s
Early stopping.
Best valid loss was 0.687228 at epoch 3.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
xVal.shape (2190, 2)
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.533333333333
Error rate (%):  46.6666666667
[[  75 1020]
 [   2 1093]]
roc_auc: 0.495945455683
log_loss: 0.690780709595
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
roc_auc for the hours: 0.476712328767
log_loss for the hours: 1.37552765824
saving predictions to csv file
hourspatient1_11_net12_10-04-20-01-33.csv
Accuracy validation for the hours:  0.153846153846
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [11]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.101983744
saving predictions to csv file
patient1_11_net12_10-04-20-05-16.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_12']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_12'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 20:05:17.354877
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_12']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [12]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.80943104
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 194.413856506 178.851933289
20 463.675524902 446.537554932
30 666.165478516 644.010736084
40 859.942541504 831.373522949
50 1065.9508667 1029.34899902
60 1304.29125977 1256.71569824
70 1606.91943359 1543.18864746
80 2047.88012695 1958.46350098
90 2871.70686035 2742.33198242
100 68176.640625 59867.6914062
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m23.09182[0m     [32m2.45175[0m    9.41851      0.49144  6.93s
      2     [36m1.11188[0m     [32m0.92438[0m    1.20283      0.50000  7.11s
      3     [36m0.77477[0m     [32m0.70547[0m    1.09822      0.54110  7.09s
      4     [36m0.69324[0m     [32m0.69691[0m    0.99474      0.55479  6.99s
      5     [36m0.67833[0m     [32m0.68728[0m    0.98697      0.55308  7.03s
      6     [36m0.67008[0m     0.68809    0.97383      0.56678  7.04s
      7     [36m0.66388[0m     0.71906    0.92326      0.54623  7.08s
      8     [36m0.66327[0m     0.73052    0.90794      0.54452  7.36s
      9     [36m0.66258[0m     0.74808    0.88570      0.53767  7.39s
     10     0.66346     0.75882    0.87433      0.53938  7.36s
     11     [36m0.66226[0m     0.76978    0.86033      0.54795  7.31s
     12     [36m0.65842[0m     0.77986    0.84428      0.54623  7.29s
     13     [36m0.65740[0m     0.77704    0.84603      0.53938  7.45s
     14     [36m0.65654[0m     0.78150    0.84009      0.55479  7.40s
     15     [36m0.65485[0m     0.80687    0.81160      0.54452  7.49s
Early stopping.
Best valid loss was 0.687283 at epoch 5.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
xVal.shape (2190, 2)
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.551141552511
Error rate (%):  44.8858447489
[[ 112  983]
 [   0 1095]]
roc_auc: 0.473649840495
log_loss: 0.691000035436
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
roc_auc for the hours: 0.512328767123
log_loss for the hours: 2.03444301705
saving predictions to csv file
hourspatient1_12_net12_10-04-20-12-19.csv
Accuracy validation for the hours:  0.153846153846
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [12]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.103138816
saving predictions to csv file
patient1_12_net12_10-04-20-15-59.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_13']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_13'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 20:16:00.372254
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_13']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [13]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.810483712
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 197.41583252 182.761578369
20 473.741113281 459.648413086
30 683.193365479 665.443499756
40 884.565112305 862.165649414
50 1098.331604 1068.85339355
60 1343.71057129 1304.4578125
70 1651.5090332 1598.25623779
80 2090.38417969 2016.00366211
90 2902.72646484 2791.59272461
100 37327.25 36955.34375
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m14.22254[0m     [32m0.69575[0m   20.44194      0.47945  6.94s
      2     [36m0.95118[0m     0.72447    1.31294      0.50000  7.12s
      3     [36m0.72684[0m     0.69983    1.03860      0.47603  7.01s
      4     [36m0.68167[0m     [32m0.68982[0m    0.98819      0.42979  7.06s
      5     [36m0.68062[0m     [32m0.68711[0m    0.99056      0.49829  6.98s
      6     [36m0.67348[0m     [32m0.67896[0m    0.99192      0.55308  7.02s
      7     [36m0.66901[0m     0.68672    0.97420      0.56164  7.00s
      8     [36m0.66568[0m     0.68242    0.97547      0.54966  6.93s
      9     [36m0.66322[0m     0.68629    0.96638      0.55479  7.25s
     10     0.66552     0.68472    0.97195      0.55993  7.35s
     11     [36m0.66107[0m     0.69114    0.95648      0.58048  7.38s
     12     0.66280     0.68403    0.96897      0.56849  7.48s
     13     [36m0.65506[0m     [32m0.67842[0m    0.96558      0.58562  7.34s
     14     [36m0.65298[0m     [32m0.66845[0m    0.97686      0.58562  7.46s
     15     0.65447     0.67704    0.96666      0.57705  7.32s
     16     0.65874     0.67292    0.97893      0.56507  7.38s
     17     [36m0.64534[0m     0.68388    0.94365      0.56164  7.30s
     18     0.65138     0.67628    0.96317      0.56678  7.41s
     19     0.64778     0.67396    0.96115      0.56336  7.39s
     20     0.64536     [32m0.66131[0m    0.97588      0.60959  7.46s
     21     [36m0.64115[0m     0.67336    0.95217      0.57705  7.34s
     22     0.64564     [32m0.64602[0m    0.99940      0.60103  7.38s
     23     [36m0.63907[0m     0.66038    0.96773      0.59075  7.36s
     24     [36m0.63212[0m     0.65482    0.96534      0.59589  7.27s
     25     0.63276     [32m0.63624[0m    0.99452      0.61986  7.38s
     26     [36m0.63072[0m     0.64897    0.97189      0.59418  7.31s
     27     0.63132     0.63649    0.99187      0.61815  7.39s
     28     [36m0.62252[0m     0.64226    0.96926      0.59247  7.42s
     29     0.62281     0.64873    0.96004      0.59418  7.52s
     30     0.68048     0.67858    1.00279      0.59589  7.42s
     31     0.69233     0.71461    0.96882      0.57192  7.40s
     32     0.64821     [32m0.63351[0m    1.02321      0.60616  7.46s
     33     0.62774     0.64097    0.97936      0.63185  7.41s
     34     [36m0.62194[0m     [32m0.62447[0m    0.99595      0.62329  7.39s
     35     [36m0.61682[0m     0.64434    0.95728      0.63014  7.45s
     36     0.61788     0.63978    0.96578      0.64555  7.45s
     37     [36m0.60402[0m     0.64034    0.94328      0.63699  7.38s
     38     0.61202     0.64152    0.95401      0.63870  7.44s
     39     0.61354     0.65225    0.94064      0.61473  7.22s
     40     [36m0.60146[0m     0.63529    0.94675      0.65068  7.31s
     41     [36m0.59702[0m     0.64348    0.92780      0.60103  7.36s
     42     0.60010     0.63090    0.95117      0.61130  7.32s
     43     [36m0.59300[0m     0.69475    0.85354      0.60959  7.43s
     44     0.60861     0.67864    0.89680      0.58390  7.43s
Early stopping.
Best valid loss was 0.624467 at epoch 34.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
xVal.shape (2190, 2)
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.626940639269
Error rate (%):  37.3059360731
[[375 720]
 [ 97 998]]
roc_auc: 0.654322887346
log_loss: 0.641014716294
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
roc_auc for the hours: 0.706849315068
log_loss for the hours: 0.783019411054
saving predictions to csv file
hourspatient1_13_net12_10-04-20-27-56.csv
Accuracy validation for the hours:  0.576923076923
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [13]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.102819328
saving predictions to csv file
patient1_13_net12_10-04-20-31-42.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_14']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_14'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 20:31:43.180495
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_14']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [14]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.809373696
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 189.141261292 174.980825806
20 452.630731201 438.836401367
30 649.66987915 632.660009766
40 836.557116699 814.948742676
50 1031.56469727 1003.98742676
60 1251.25163574 1216.06953125
70 1519.30529785 1471.67954102
80 1885.33984375 1820.3204834
90 2516.96833496 2415.86462402
100 43412.1367188 33402.015625
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m13.54157[0m     [32m0.88597[0m   15.28447      0.50000  7.01s
      2     [36m1.08334[0m     [32m0.83707[0m    1.29420      0.50000  6.99s
      3     [36m0.72930[0m     [32m0.69791[0m    1.04497      0.52397  6.91s
      4     [36m0.68999[0m     [32m0.68892[0m    1.00155      0.53596  6.96s
      5     [36m0.68062[0m     0.70323    0.96785      0.52055  6.96s
      6     [36m0.67733[0m     0.70392    0.96222      0.52568  7.21s
      7     [36m0.67268[0m     0.72423    0.92882      0.51884  6.95s
      8     [36m0.66933[0m     0.73976    0.90478      0.52055  7.36s
      9     0.67008     0.76824    0.87222      0.52740  7.41s
     10     [36m0.66604[0m     0.79324    0.83964      0.51884  7.28s
     11     [36m0.66599[0m     0.80865    0.82359      0.52397  7.42s
     12     [36m0.66485[0m     0.81499    0.81577      0.52055  7.42s
     13     [36m0.66181[0m     0.81694    0.81011      0.52055  7.26s
     14     [36m0.66023[0m     0.83071    0.79478      0.52226  7.32s
Early stopping.
Best valid loss was 0.688916 at epoch 4.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
xVal.shape (2190, 2)
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.521461187215
Error rate (%):  47.8538812785
[[  47 1048]
 [   0 1095]]
roc_auc: 0.552060632597
log_loss: 0.69332830827
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
roc_auc for the hours: 0.627397260274
log_loss for the hours: 1.9419614304
saving predictions to csv file
hourspatient1_14_net12_10-04-20-38-42.csv
Accuracy validation for the hours:  0.115384615385
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [14]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.103306752
saving predictions to csv file
patient1_14_net12_10-04-20-42-23.csv
['python', 'train.py', '--debug-sub-ratio=1', '--config-filename=config4.yml', '--no-channels=1', '--target-gpu=gpu1', '--data-path=/home/eavsteen/seizure_detection/data', '--patients=patient1_15']
init done
Command line arguments: Namespace(chosen_validation_ratio=0.2, config_filename='config4.yml', data_path='/home/eavsteen/seizure_detection/data', debug_sub_ratio=1.0, exclude_user=[], fixed_seed=True, include_user=[], mode='None', model_path='/home/eavsteen/seizure_detection/vault', no_channels=1, no_predict_test=False, no_preprocessing=False, no_save_model=False, no_training=False, patients=['patient1_15'], plot_prob_dist=False, save_preprocessed=False, shift=0, shuffle_before_split=True, target_gpu='gpu1')
Git reference:  Timestamp: 2016-10-04 20:42:24.753888
Hostname: kat
gpu1
Configuration 'config4.yml':
Configuration:
preprocess:
    floor: 0
    ceil: 64
    fft_width: 1024
    overlap: 0
    magnitude_window: 192
    augmentation: shift
    normalization: min_max_x255
    include_userdata: false
training:
    model: net12
evaluation:
    online_training: False
    model: net12

end Configuration
['patient1_15']
<type 'list'>
Loading and preprocessing data...
total
365
25
train
292
20
validation
73
5
test_magnitude.shape (1406, 64)
20
5
292
73
Read in dataset from train_2 ...
Processing data ...
read data and preprocess (fft and slicing)
read in channels [15]
/home/eavsteen/seizure_detection/data/train_2/2_
normal i 0
normal i 1
normal i 2
normal i 3
normal i 4
normal i 5
normal i 6
normal i 7
normal i 8
normal i 9
normal i 10
normal i 11
normal i 12
normal i 13
normal i 14
normal i 15
normal i 16
normal i 17
normal i 18
normal i 19
normal i 20
normal i 21
normal i 22
normal i 23
normal i 24
normal i 25
normal i 26
normal i 27
normal i 28
normal i 29
normal i 30
normal i 31
normal i 32
normal i 33
normal i 34
normal i 35
normal i 36
normal i 37
normal i 38
normal i 39
normal i 40
normal i 41
normal i 42
normal i 43
normal i 44
normal i 45
normal i 46
normal i 47
normal i 48
normal i 49
normal i 50
normal i 51
normal i 52
normal i 53
normal i 54
normal i 55
normal i 56
normal i 57
normal i 58
normal i 59
normal i 60
normal i 61
normal i 62
normal i 63
normal i 64
normal i 65
normal i 66
normal i 67
normal i 68
normal i 69
normal i 70
normal i 71
normal i 72
normal i 73
normal i 74
normal i 75
normal i 76
normal i 77
normal i 78
normal i 79
normal i 80
normal i 81
normal i 82
normal i 83
normal i 84
normal i 85
normal i 86
normal i 87
normal i 88
normal i 89
normal i 90
normal i 91
normal i 92
normal i 93
normal i 94
normal i 95
normal i 96
normal i 97
normal i 98
normal i 99
normal i 100
normal i 101
normal i 102
normal i 103
normal i 104
normal i 105
normal i 106
normal i 107
normal i 108
normal i 109
normal i 110
normal i 111
normal i 112
normal i 113
normal i 114
normal i 115
normal i 116
normal i 117
normal i 118
normal i 119
normal i 120
normal i 121
normal i 122
normal i 123
normal i 124
normal i 125
normal i 126
normal i 127
normal i 128
normal i 129
normal i 130
normal i 131
normal i 132
normal i 133
normal i 134
normal i 135
normal i 136
normal i 137
normal i 138
normal i 139
normal i 140
normal i 141
normal i 142
normal i 143
normal i 144
normal i 145
normal i 146
normal i 147
normal i 148
normal i 149
normal i 150
normal i 151
normal i 152
normal i 153
normal i 154
normal i 155
normal i 156
normal i 157
normal i 158
normal i 159
normal i 160
normal i 161
normal i 162
normal i 163
normal i 164
normal i 165
normal i 166
normal i 167
normal i 168
normal i 169
normal i 170
normal i 171
normal i 172
normal i 173
normal i 174
normal i 175
normal i 176
normal i 177
normal i 178
normal i 179
normal i 180
normal i 181
normal i 182
normal i 183
normal i 184
normal i 185
normal i 186
normal i 187
normal i 188
normal i 189
normal i 190
normal i 191
normal i 192
normal i 193
normal i 194
normal i 195
normal i 196
normal i 197
normal i 198
normal i 199
normal i 200
normal i 201
normal i 202
normal i 203
normal i 204
normal i 205
normal i 206
normal i 207
normal i 208
normal i 209
normal i 210
normal i 211
normal i 212
normal i 213
normal i 214
normal i 215
normal i 216
normal i 217
normal i 218
normal i 219
normal i 220
normal i 221
normal i 222
normal i 223
normal i 224
normal i 225
normal i 226
normal i 227
normal i 228
normal i 229
normal i 230
normal i 231
normal i 232
normal i 233
normal i 234
normal i 235
normal i 236
normal i 237
normal i 238
normal i 239
normal i 240
normal i 241
normal i 242
normal i 243
normal i 244
normal i 245
normal i 246
normal i 247
normal i 248
normal i 249
normal i 250
normal i 251
normal i 252
normal i 253
normal i 254
normal i 255
normal i 256
normal i 257
normal i 258
normal i 259
normal i 260
normal i 261
normal i 262
normal i 263
normal i 264
normal i 265
normal i 266
normal i 267
normal i 268
normal i 269
normal i 270
normal i 271
normal i 272
normal i 273
normal i 274
normal i 275
normal i 276
normal i 277
normal i 278
normal i 279
normal i 280
normal i 281
normal i 282
normal i 283
normal i 284
normal i 285
normal i 286
normal i 287
normal i 288
normal i 289
normal i 290
normal i 291
normal i 292
normal i 293
normal i 294
normal i 295
normal i 296
normal i 297
normal i 298
normal i 299
normal i 300
normal i 301
normal i 302
normal i 303
normal i 304
normal i 305
normal i 306
normal i 307
normal i 308
normal i 309
normal i 310
normal i 311
normal i 312
normal i 313
normal i 314
normal i 315
normal i 316
normal i 317
normal i 318
normal i 319
normal i 320
normal i 321
normal i 322
normal i 323
normal i 324
normal i 325
normal i 326
normal i 327
normal i 328
normal i 329
normal i 330
normal i 331
normal i 332
normal i 333
normal i 334
normal i 335
normal i 336
normal i 337
normal i 338
normal i 339
normal i 340
normal i 341
normal i 342
normal i 343
normal i 344
normal i 345
normal i 346
normal i 347
normal i 348
normal i 349
normal i 350
normal i 351
normal i 352
normal i 353
normal i 354
normal i 355
normal i 356
normal i 357
normal i 358
normal i 359
normal i 360
normal i 361
normal i 362
normal i 363
normal i 364
seizure i 0
seizure i 1
seizure i 2
seizure i 3
seizure i 4
seizure i 5
seizure i 6
seizure i 7
seizure i 8
seizure i 9
seizure i 10
seizure i 11
seizure i 12
seizure i 13
seizure i 14
seizure i 15
seizure i 16
seizure i 17
seizure i 18
seizure i 19
seizure i 20
seizure i 21
seizure i 22
seizure i 23
seizure i 24
Done reading in 365 no seizure hours and 25 seizure hours
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
Memory usage (GB): 0.81035264
train_counter_seizure 20 val_counter_seizure 5
train_counter_normal 292 val_counter_normal 73
percentiles:
0 0.0 0.0
10 192.412426758 176.768930054
20 459.689099121 442.431689453
30 658.81307373 637.209912109
40 846.730224609 819.873974609
50 1042.01245117 1009.00811768
60 1261.45869141 1219.99689941
70 1528.8362793 1476.44569092
80 1896.24025879 1829.35996094
90 2539.709375 2448.71398926
100 29197.0292969 29615.0136719
Histogram:
[1460 1460]
yTrain.shape (2920,)
xTrain.shape (2920,)
Histogram:
[1095 1095]
yTrain.shape (2920,)
xTrain.shape (2190,)
xVal.shape (2190,)
yVal.shape (2190,)
Ratio validation: 0.2
xTrain.shape (2920,)
yTrain.shape (2920,)
xVal.shape (2190, 2)
yVal.shape (2190,)
Building models ...
Model name for the training phase:  net12
Model name for the evaluation phase:  net12
Training model...
# Neural Network with 540034 learnable parameters

## Layer information

  #    name  size
---  ------  ---------
  0          1x192x64
  1          32x192x64
  2          64x192x64
  3          64x192x64
  4          128x96x32
  5          128x96x32
  6          128x96x32
  7          256x48x16
  8          2x48x16
  9          2
 10          2

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  -----
      1    [36m13.86462[0m     [32m1.12035[0m   12.37528      0.50000  6.84s
      2     [36m1.09176[0m     [32m0.90334[0m    1.20859      0.50000  6.82s
      3     [36m0.73541[0m     [32m0.68719[0m    1.07016      0.52740  6.70s
      4     [36m0.68735[0m     [32m0.68497[0m    1.00346      0.54795  6.75s
      5     [36m0.67492[0m     0.69230    0.97489      0.52740  6.78s
      6     [36m0.67207[0m     0.69038    0.97348      0.55651  6.78s
      7     [36m0.66797[0m     0.69419    0.96223      0.55479  6.81s
      8     [36m0.66511[0m     0.70792    0.93953      0.56336  6.76s
      9     [36m0.66261[0m     0.70801    0.93587      0.54623  7.09s
     10     [36m0.66224[0m     0.73456    0.90154      0.54623  7.09s
     11     0.66247     0.73663    0.89932      0.55137  7.08s
     12     [36m0.66214[0m     0.74535    0.88836      0.54281  7.15s
     13     [36m0.65986[0m     0.75594    0.87290      0.53596  7.18s
     14     [36m0.65740[0m     0.76856    0.85537      0.54281  7.08s
Early stopping.
Best valid loss was 0.684975 at epoch 4.
Loaded parameters to layer 'conv2d1' (shape 32x1x3x3).
Loaded parameters to layer 'conv2d1' (shape 32).
Loaded parameters to layer 'conv2d2' (shape 64x32x3x3).
Loaded parameters to layer 'conv2d2' (shape 64).
Loaded parameters to layer 'conv2d4' (shape 128x64x3x3).
Loaded parameters to layer 'conv2d4' (shape 128).
Loaded parameters to layer 'conv2d5' (shape 128x128x3x3).
Loaded parameters to layer 'conv2d5' (shape 128).
Loaded parameters to layer 'conv2d7' (shape 256x128x3x3).
Loaded parameters to layer 'conv2d7' (shape 256).
Loaded parameters to layer 'conv2d8' (shape 2x256x3x3).
Loaded parameters to layer 'conv2d8' (shape 2).
Saving model...
Validating...
xVal.shape (2190, 2)
probabilities.shape (2190, 2)
Showing last 30 test samples..
Predictions:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Ground Truth:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Performance on relevant data
Accuracy validation:  0.525114155251
Error rate (%):  47.4885844749
[[  55 1040]
 [   0 1095]]
roc_auc: 0.590107795918
log_loss: 0.690011734737
Changing batch iterator test:
Calculating final prediction for the hour long sessions
magnitudes_normal_val.shape (73, 1, 1406, 64)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
(1, 1215, 1, 192, 64)
(1, 1215, 1, 192, 64)
(1215, 2)
(2,)
magnitudes_seizure_val.shape (5, 1, 1406, 64)
roc_auc for the hours: 0.619178082192
log_loss for the hours: 1.85446497738
saving predictions to csv file
hourspatient1_15_net12_10-04-20-49-02.csv
Accuracy validation for the hours:  0.128205128205
Calculating the predictions for the test files
Loading and preprocessing data...
no_files 2256
test_magnitude.shape (234, 64)
(2256, 1, 234, 64)
Read in dataset from test_2 ...
read data and preprocess (fft and slicing)
read in channels [15]
/home/eavsteen/seizure_detection/data/test_2/2_
Done reading in 2256 test snippets of 10min.
Memory usage (GB): 1.104482304
saving predictions to csv file
patient1_15_net12_10-04-20-52-39.csv
